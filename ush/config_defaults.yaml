#----------------------------
# Test description
#----------------------------
metadata:
  description: >-
    Default configuration for an experiment. The valid values for most of the
    parameters are specified in valid_param_vals.yaml
  version: !!str '2.0'
#----------------------------
# USER config parameters
#----------------------------
user:
  #
  #-----------------------------------------------------------------------
  #
  # Set the RUN_ENVIR variable that is listed and described in the WCOSS
  # Implementation Standards document:
  #
  #   NCEP Central Operations
  #   WCOSS Implementation Standards
  #   April 19, 2022
  #   Version 11.0.0
  #
  # RUN_ENVIR is described in this document as follows:
  #
  #   Set to "nco" if running in NCO's production environment. Used to 
  #   distinguish between organizations.
  #
  # Valid values are "nco" and "community".  Here, we use it to generate
  # and run the experiment either in NCO mode (if RUN_ENVIR is set to "nco")
  # or in community mode (if RUN_ENVIR is set to "community").  This has 
  # implications on the experiment variables that need to be set and the
  # the directory structure used.
  #
  #-----------------------------------------------------------------------
  #
  RUN_ENVIR: "nco"
  #
  #-----------------------------------------------------------------------
  #
  # Set machine and queue parameters.  Definitions:
  #
  # MACHINE:
  # Machine on which the workflow will run. If you are NOT on a named,
  # supported platform, and you want to use the Rocoto workflow manager,
  # you will need set MACHINE: "linux" and WORKFLOW_MANAGER: "rocoto". This
  # combination will assume a Slurm batch manager when generating the XML.
  # Please see ush/valid_param_vals.yaml for a full list of supported
  # platforms.
  #
  # ACCOUNT:
  # The account under which to submit jobs to the queue.
  #
  # SERVICE_ACCOUNT:
  # The account under which to submit non-reservation jobs to the queue.
  # Defaults to ACCOUNT if not set.
  #
  #-----------------------------------------------------------------------
  MACHINE: "BIG_COMPUTER"
  ACCOUNT: ""
  SERVICE_ACCOUNT: ""

  HOMEdir: '{{ user.HOMEdir }}'
  USHdir: '{{ user.USHdir }}'
  SCRIPTSdir: '{{ [HOMEdir, "scripts"]|path_join }}'
  JOBSdir: '{{ [HOMEdir, "jobs"]|path_join }}'
  SORCdir: '{{ [HOMEdir, "sorc"]|path_join }}'
  PARMdir: '{{ [HOMEdir, "parm"]|path_join }}'
  MODULESdir: '{{ [HOMEdir, "modulefiles"]|path_join }}'
  EXECdir: '{{ [HOMEdir, workflow.EXEC_SUBDIR]|path_join }}'
  GRAPHICSdir: '{{ [HOMEdir, "python_graphics"]|path_join }}'
  VX_CONFIG_DIR: '{{ [HOMEdir, "parm"]|path_join }}'
  METPLUS_CONF: '{{ [PARMdir, "metplus"]|path_join }}'
  MET_CONFIG: '{{ [PARMdir, "met"]|path_join }}'
  UFS_WTHR_MDL_DIR: '{{ user.UFS_WTHR_MDL_DIR }}'
  ARL_NEXUS_DIR: '{{ [SORCdir, "arl_nexus"]|path_join }}'

#----------------------------
# PLATFORM config parameters
#-----------------------------
platform:
  #
  #-----------------------------------------------------------------------
  #
  # WORKFLOW_MANAGER:
  # The workflow manager to use (e.g. rocoto). This is set to "none" by
  # default, but if the machine name is set to a platform that supports
  # rocoto, this will be overwritten and set to "rocoto". If set
  # explicitly to rocoto along with the use of the MACHINE=linux target,
  # the configuration layer assumes a Slurm batch manager when generating
  # the XML. Valid options: "rocoto" or "none"
  #
  # NCORES_PER_NODE:
  # The number of cores available per node on the compute platform, now 
  # configurable for all platforms.
  #
  # TASKTHROTTLE:
  # The number of active tasks run simultaneously. For linux/mac setting this
  # to 1 makes sense
  #
  # BUILD_MOD_FN:
  # Name of alternative build module file to use if using an
  # unsupported platform. Is set automatically for supported machines.
  #
  # WFLOW_MOD_FN:
  # Name of alternative workflow module file to use if using an
  # unsupported platform. Is set automatically for supported machines.
  #
  # BUILD_VER_FN:
  # File name containing the version of the modules used for building the app.
  # Currently, WCOSS2 only uses this file.
  #
  # RUN_VER_FN:
  # File name containing the version of the modules used for running the app.
  # Currently, WCOSS2 only uses this file.
  #
  # SCHED:
  # The job scheduler to use (e.g. slurm).  Set this to an empty string in
  # order for the experiment generation script to set it depending on the
  # machine.
  #
  # PARTITION_DEFAULT:
  # If using the slurm job scheduler (i.e. if SCHED is set to "slurm"), 
  # the default partition to which to submit workflow tasks.  If a task 
  # does not have a specific variable that specifies the partition to which 
  # it will be submitted (e.g. PARTITION_HPSS, PARTITION_FCST; see below), 
  # it will be submitted to the partition specified by this variable.  If 
  # this is not set or is set to an empty string, it will be (re)set to a 
  # machine-dependent value.  This is not used if SCHED is not set to 
  # "slurm".
  #
  # QUEUE_DEFAULT:
  # The default queue or QOS (if using the slurm job scheduler, where QOS
  # is Quality of Service) to which workflow tasks are submitted.  If a 
  # task does not have a specific variable that specifies the queue to which 
  # it will be submitted (e.g. QUEUE_HPSS, QUEUE_FCST; see below), it will 
  # be submitted to the queue specified by this variable.  If this is not 
  # set or is set to an empty string, it will be (re)set to a machine-
  # dependent value.
  #
  # PARTITION_HPSS:
  # If using the slurm job scheduler (i.e. if SCHED is set to "slurm"), 
  # the partition to which the tasks that get or create links to external 
  # model files [which are needed to generate initial conditions (ICs) and 
  # lateral boundary conditions (LBCs)] are submitted.  If this is not set 
  # or is set to an empty string, it will be (re)set to a machine-dependent 
  # value.  This is not used if SCHED is not set to "slurm".
  #
  # QUEUE_HPSS:
  # The queue or QOS to which the tasks that get or create links to external 
  # model files [which are needed to generate initial conditions (ICs) and 
  # lateral boundary conditions (LBCs)] are submitted.  If this is not set 
  # or is set to an empty string, it will be (re)set to a machine-dependent 
  # value.
  #
  # PARTITION_FCST:
  # If using the slurm job scheduler (i.e. if SCHED is set to "slurm"), 
  # the partition to which the task that runs forecasts is submitted.  If 
  # this is not set or set to an empty string, it will be (re)set to a 
  # machine-dependent value.  This is not used if SCHED is not set to 
  # "slurm".
  #
  # QUEUE_FCST:
  # The queue or QOS to which the task that runs a forecast is submitted.  
  # If this is not set or set to an empty string, it will be (re)set to a 
  # machine-dependent value.
  #
  # PARTITION_GRAPHICS
  # Partition to which graphics tasks are submitted
  #
  # QUEUE_GRAPHICS
  # Queue for graphics tasks
  #
  # PARTITION_ANALYSIS
  # Partion to which analysis tasks are submitted
  #
  # QUEUE_ANALYSIS:
  # The queue or QOS to which the task that runs a analysis is submitted.  
  # If this is not set or set to an empty string, it will be (re)set to a 
  # machine-dependent value.
  #
  # PARTITION_PRDGEN:
  # If using the slurm job scheduler (i.e. if SCHED is set to "slurm"), 
  # the partition to which the task that remaps output grids is submitted.  If 
  # this is not set or set to an empty string, it will be (re)set to a 
  # machine-dependent value.  This is not used if SCHED is not set to 
  # "slurm".
  #
  # QUEUE_PRDGEN:
  # The queue or QOS to which the task that prodgen is submitted.  
  # If this is not set or set to an empty string, it will be (re)set to a 
  # machine-dependent value.
  #
  # PARTITION_POST:
  # If using the slurm job scheduler (i.e. if SCHED is set to "slurm"), 
  # the partition to which the task that upp is submitted.
  #
  # QUEUE_POST:
  # The queue or QOS to which the task that upp is submitted.  
  # If this is not set or set to an empty string, it will be (re)set to a 
  # machine-dependent value.
  #
  # RESERVATION:
  # The reservation for major tasks.  
  #
  # RESERVATION_POST:
  # The reservation for post tasks.  
  #
  #-----------------------------------------------------------------------
  #
  WORKFLOW_MANAGER: ""
  NCORES_PER_NODE: ""
  TASKTHROTTLE: 1000
  BUILD_MOD_FN: 'build_{{ user.MACHINE|lower() }}_{{ workflow.COMPILER }}'
  WFLOW_MOD_FN: 'wflow_{{ user.MACHINE|lower() }}'
  BUILD_VER_FN: 'build.ver.{{ user.MACHINE|lower() }}'
  RUN_VER_FN: 'run.ver.{{ user.MACHINE|lower() }}'
  RESERVATION: ""
  RESERVATION_POST: ""
  SCHED: ""
  PARTITION_DEFAULT: ""
  QUEUE_DEFAULT: ""
  PARTITION_HPSS: ""
  QUEUE_HPSS: ""
  PARTITION_FCST: ""
  QUEUE_FCST: ""
  PARTITION_GRAPHICS: ""
  QUEUE_GRAPHICS: ""
  PARTITION_ANALYSIS: ""
  QUEUE_ANALYSIS: ""
  PARTITION_PRDGEN: ""
  QUEUE_PRDGEN: ""
  PARTITION_POST: ""
  QUEUE_POST: ""
  #
  #-----------------------------------------------------------------------
  #
  # Set run commands for platforms without a workflow manager. These values
  # will be ignored unless WORKFLOW_MANAGER: "none".  Definitions:
  #
  # RUN_CMD_UTILS:
  # The run command for pre-processing utilities (shave, orog, sfc_climo_gen, 
  # etc.) Can be left blank for smaller domains, in which case the executables 
  # will run without MPI.
  #
  # RUN_CMD_FCST:
  # The run command for the model forecast step. 
  #
  # RUN_CMD_POST:
  # The run command for post-processing (UPP). Can be left blank for smaller 
  # domains, in which case UPP will run without MPI.
  #
  # RUN_CMD_SERIAL:
  # The run command for some serial jobs 
  #
  # RUN_CMD_AQM:
  # The run command for some AQM tasks.
  #
  #-----------------------------------------------------------------------
  #
  RUN_CMD_SERIAL: ""
  RUN_CMD_UTILS: ""
  RUN_CMD_FCST: ""
  RUN_CMD_POST: ""
  RUN_CMD_AQM: ""

  #
  #-----------------------------------------------------------------------
  #
  # SCHED_NATIVE_CMD
  # Allows an extra parameter to be passed to SCHEDULER (SLURM/PBSPRO) via 
  # XML Native command
  #
  #-----------------------------------------------------------------------
  #
  SCHED_NATIVE_CMD: ""
  #
  #-----------------------------------------------------------------------
  #
  # Set METplus parameters.  Definitions:
  #
  # MET_INSTALL_DIR:
  # Location to top-level directory of MET installation.
  #
  # MET_BIN_EXEC:
  # Subdirectory containing MET binaries e.g. "bin"
  #
  # METPLUS_PATH:
  # Location to top-level directory of METplus installation.
  #
  # MET_BIN_EXEC
  # Name of subdirectory where METplus executables are installed.
  #
  # CCPA_OBS_DIR:
  # User-specified location of top-level directory where CCPA hourly
  # precipitation files used by METplus are located. This parameter needs
  # to be set for both user-provided observations and for observations 
  # that are retrieved from the NOAA HPSS (if the user has access) via
  # the TN_GET_OBS_CCPA task (activated in workflow by setting
  # RUN_TASK_GET_OBS_CCPA=true). In the case of pulling observations 
  # directly from NOAA HPSS, the data retrieved will be placed in this 
  # directory. Please note, this path must be defind as 
  # /full-path-to-obs/ccpa/proc. METplus is configured to verify 01-, 
  # 03-, 06-, and 24-h accumulated precipitation using hourly CCPA files.
  # METplus configuration files require the use of predetermined directory 
  # structure and file names. Therefore, if the CCPA files are user 
  # provided, they need to follow the anticipated naming structure: 
  # {YYYYMMDD}/ccpa.t{HH}z.01h.hrap.conus.gb2, where YYYY is the 4-digit 
  # valid year, MM the 2-digit valid month, DD the 2-digit valid day of 
  # the month, and HH the 2-digit valid hour of the day. In addition, a 
  # caveat is noted for using hourly CCPA data. There is a problem with 
  # the valid time in the metadata for files valid from 19 - 00 UTC (or 
  # files under the '00' directory). The script to pull the CCPA data 
  # from the NOAA HPSS has an example of how to account for this as well
  # as organizing the data into a more intuitive format:
  # scripts/exregional_get_ccpa_files.sh. When a fix is provided, it will
  # be accounted for in the exregional_get_ccpa_files.sh script.
  #
  # MRMS_OBS_DIR:
  # User-specified location of top-level directory where MRMS composite
  # reflectivity files used by METplus are located.  This parameter needs
  # to be set for both user-provided observations and for observations
  # that are retrieved from the NOAA HPSS (if the user has access) via the
  # TN_GET_OBS_MRMS task (activated in workflow by setting
  # RUN_TASK_GET_OBS_MRMS=true).  In the case of pulling observations 
  # directly from NOAA HPSS, the data retrieved will be placed in this 
  # directory. Please note, this path must be defind as 
  # /full-path-to-obs/mrms/proc. METplus configuration files require the
  # use of predetermined directory structure and file names. Therefore, if
  # the MRMS files are user provided, they need to follow the anticipated 
  # naming structure:
  # {YYYYMMDD}/MergedReflectivityQCComposite_00.50_{YYYYMMDD}-{HH}{mm}{SS}.grib2,
  # where YYYY is the 4-digit valid year, MM the 2-digit valid month, DD 
  # the 2-digit valid day of the month, HH the 2-digit valid hour of the 
  # day, mm the 2-digit valid minutes of the hour, and SS is the two-digit
  # valid seconds of the hour. In addition, METplus is configured to look
  # for a MRMS composite reflectivity file for the valid time of the 
  # forecast being verified; since MRMS composite reflectivity files do 
  # not always exactly match the valid time, a script, within the main 
  # script to retrieve MRMS data from the NOAA HPSS, is used to identify
  # and rename the MRMS composite reflectivity file to match the valid
  # time of the forecast.  The script to pull the MRMS data from the NOAA 
  # HPSS has an example of the expected file naming structure: 
  # scripts/exregional_get_mrms_files.sh. This script calls the script
  # used to identify the MRMS file closest to the valid time:
  # ush/mrms_pull_topofhour.py.
  #
  # NDAS_OBS_DIR:
  # User-specified location of top-level directory where NDAS prepbufr 
  # files used by METplus are located. This parameter needs to be set for
  # both user-provided observations and for observations that are 
  # retrieved from the NOAA HPSS (if the user has access) via the 
  # TN_GET_OBS_NDAS task (activated in workflow by setting 
  # RUN_TASK_GET_OBS_NDAS=true). In the case of pulling observations 
  # directly from NOAA HPSS, the data retrieved will be placed in this 
  # directory. Please note, this path must be defind as 
  # /full-path-to-obs/ndas/proc. METplus is configured to verify 
  # near-surface variables hourly and upper-air variables at times valid 
  # at 00 and 12 UTC with NDAS prepbufr files.  METplus configuration files
  # require the use of predetermined file names. Therefore, if the NDAS 
  # files are user provided, they need to follow the anticipated naming 
  # structure: prepbufr.ndas.{YYYYMMDDHH}, where YYYY is the 4-digit valid
  # year, MM the 2-digit valid month, DD the 2-digit valid day of the 
  # month, and HH the 2-digit valid hour of the day. The script to pull 
  # the NDAS data from the NOAA HPSS has an example of how to rename the
  # NDAS data into a more intuitive format with the valid time listed in 
  # the file name: scripts/exregional_get_ndas_files.sh
  #
  #-----------------------------------------------------------------------
  #
  MET_INSTALL_DIR: ""
  MET_BIN_EXEC: ""
  METPLUS_PATH: ""
  CCPA_OBS_DIR: ""
  MRMS_OBS_DIR: ""
  NDAS_OBS_DIR: ""
  #
  #-----------------------------------------------------------------------
  #
  # DOMAIN_PREGEN_BASEDIR:
  # The base directory containing pregenerated grid, orography, and surface 
  # climatology files. This is an alternative for setting GRID_DIR,
  # OROG_DIR, and SFC_CLIMO_DIR individually
  # 
  # For the pregenerated grid specified by PREDEF_GRID_NAME, 
  # these "fixed" files are located in:
  #
  #   ${DOMAIN_PREGEN_BASEDIR}/${PREDEF_GRID_NAME}
  #
  # The workflow scripts will create a symlink in the experiment directory
  # that will point to a subdirectory (having the name of the grid being
  # used) under this directory.  This variable should be set to a null 
  # string in this file, but it can be specified in the user-specified 
  # workflow configuration file (EXPT_CONFIG_FN).
  #
  #-----------------------------------------------------------------------
  #
  DOMAIN_PREGEN_BASEDIR: ""
  #
  #-----------------------------------------------------------------------
  # Pre task commands such as "ulimit" needed by tasks
  #-----------------------------------------------------------------------
  #
  PRE_TASK_CMDS: ""
  #
  #-----------------------------------------------------------------------
  # Test directories used in run_WE2E script
  #-----------------------------------------------------------------------
  #
  TEST_EXTRN_MDL_SOURCE_BASEDIR: ""
  TEST_PREGEN_BASEDIR: ""
  TEST_ALT_EXTRN_MDL_SYSBASEDIR_ICS: ""
  TEST_ALT_EXTRN_MDL_SYSBASEDIR_LBCS: ""
  TEST_VX_FCST_INPUT_BASEDIR: ""
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters associated with the fixed (i.e. static) files.  Definitions:
  #
  # FIXgsm:
  # System directory in which the majority of fixed (i.e. time-independent) 
  # files that are needed to run the FV3-LAM model are located
  #
  # FIXaer:
  # System directory where MERRA2 aerosol climatology files are located
  #
  # FIXlut:
  # System directory where the lookup tables for optics properties are located
  #
  # FIXorg:
  # System directory where orography data is located
  #
  # FIXsfc:
  # System directory where surface climatology data is located
  #
  # FIXgsi:
  # System directory where GSI fixed files are loacated
  #
  # FIXsmoke:
  # System directory where smoke and dust fixed files are loacated
  #
  # FIXbufr:
  # System directory where bufrsnd fixed files are loacated
  #
  # FIXcrtm:
  # System directory where CRTM fixed files are loacated
  #
  # FIXcrtmupp:
  # System directory where CRTM fixed files specifically for UPP are loacated
  #
  #-----------------------------------------------------------------------
  #
  FIXgsm: ""
  FIXaer: ""
  FIXlut: ""
  FIXorg: ""
  FIXsfc: ""
  FIXshp: ""
  FIXgsi: ""
  FIXsmoke: ""
  FIXbufr: ""
  FIXcrtm: ""
  FIXcrtmupp: ""
  #
  #-----------------------------------------------------------------------
  #
  # EXTRN_MDL_DATA_STORES:
  # A list of data stores where the scripts should look for external model
  # data. The list is in priority order. If disk information is provided
  # via USE_USER_STAGED_EXTRN_FILES or a known location on the platform,
  # the disk location will be highest priority. Options are disk, hpss,
  # aws, and nomads.
  #
  #-----------------------------------------------------------------------
  #
  EXTRN_MDL_DATA_STORES: ""
  #
  #-----------------------------------------------------------------------
  #
  # Setup default observation locations for data assimilation:
  #
  #    OBSPATH:   observation BUFR file path
  #    OBSPATH_NSSLMOSIAC: location of NSSL radar reflectivity 
  #    LIGHTNING_ROOT: location of lightning observations
  #    ENKF_FCSTL: location of global ensemble forecast
  #    FFG_DIR: location of flash flood guidance for QPF comparison
  #
  # Setup default locations for global SST and update time:
  #   SST_ROOT: locations of global SST
  #   SST_update_hour: cycle time for updating SST 
  #
  # Setup default locations for GVF and update time:
  #   GVF_ROOT: locations of GVF observations
  #   GVF_update_hour: cycle time for updating GVF 
  #
  # Setup default locations for IMS snow/ice and update time:
  #   IMSSNOW_ROOT: locations of IMS snow/ice observations
  #   SNOWICE_update_hour: cycle time for updating snow/ice 
  #
  # Setup default resource data locations for soil surgery and time:
  #   RAPHRR_SOIL_ROOT: locations of RAP/HRRR forecast netcdf files
  #   SOIL_SURGERY_time: cycle time for soil surgery 
  #
  # Setup default locations for FIRE_RRFS files and update time
  #  FIRE_RAVE_DIR
  #  FIRE_RRFS_update_hour
  #
  #-----------------------------------------------------------------------
  #
  ARCHIVEDIR: ""
  NCARG_ROOT: ""
  NCL_HOME: ""
  OBSPATH: ""
  OBSPATH_NSSLMOSIAC: ""
  LIGHTNING_ROOT: ""
  ENKF_FCST: ""
  FFG_DIR: ""
  SST_ROOT: ""
  GVF_ROOT: ""
  IMSSNOW_ROOT: ""
  RAPHRR_SOIL_ROOT: ""
  FIRE_RAVE_DIR: ""
  AIRCRAFT_REJECT: ""
  SFCOBS_USELIST: ""

  NCL_REGION: "conus"
  SST_update_hour: 99
  GVF_update_hour: 99
  SNOWICE_update_hour: 99
  SOIL_SURGERY_time: 9999999999
  FIRE_RRFS_update_hour: 99
  # COMINgfs:
  # Path to the real-time GFS data
  #
  # COMINgefs:
  # Path to the real-time GEFS data
  #
  # COMINairnow:
  # Path to the real-time AIRNOW observation data
  #
  #-----------------------------------------------------------------------
  #
  COMINgfs: ""
  COMINgefs: ""
  COMINairnow: "/path/to/real/time/airnow/data"

#-----------------------------
# WORKFLOW config parameters
#-----------------------------
workflow:
  #
  #-----------------------------------------------------------------------
  #
  # WORKFLOW_ID
  # Unique ID for workflow run that will be set in setup.py
  #
  # TAG
  # Append all task names of the workflow with this name if specified
  #
  #-----------------------------------------------------------------------
  #
  WORKFLOW_ID: ""
  TAG: ""
  #
  #-----------------------------------------------------------------------
  #
  # How to make links. Relative links by default. Empty string for
  # absolute paths in links.
  #
  #-----------------------------------------------------------------------
  #
  RELATIVE_LINK_FLAG: "--relative"
  #
  #-----------------------------------------------------------------------
  #
  # Set cron-associated parameters.  Definitions:
  #
  # USE_CRON_TO_RELAUNCH:
  # Flag that determines whether or not to add a line to the user's cron 
  # table to call the experiment launch script every CRON_RELAUNCH_INTVL_MNTS 
  # minutes.
  #
  # CRON_RELAUNCH_INTVL_MNTS:
  # The interval (in minutes) between successive calls of the experiment
  # launch script by a cron job to (re)launch the experiment (so that the
  # workflow for the experiment kicks off where it left off).
  #
  #-----------------------------------------------------------------------
  #
  USE_CRON_TO_RELAUNCH: false
  CRON_RELAUNCH_INTVL_MNTS: 3
  CRONTAB_LINE: ""
  LOAD_MODULES_RUN_TASK_FP: '{{ [user.USHdir, "load_modules_run_task.sh"]|path_join }}'

  #
  #-----------------------------------------------------------------------
  #
  # Set directories.  Definitions:
  #
  # EXPT_BASEDIR:
  # The base directory in which the experiment directory will be created.  
  # If this is not specified or if it is set to an empty string, it will
  # default to ${HOMEdir}/../expt_dirs. If set to a relative path, the
  # path will be appended to the default value ${HOMEdir}/../expt_dirs 
  #
  # EXPT_SUBDIR:
  # The name that the experiment directory (without the full path) will
  # have.  The full path to the experiment directory, which will be contained
  # in the variable EXPTDIR, will be:
  #
  #   EXPTDIR: "${EXPT_BASEDIR}/${EXPT_SUBDIR}"
  #
  # This cannot be empty.  If set to a null string here, it must be set to
  # a (non-empty) value in the user-defined experiment configuration file.
  #
  # EXEC_SUBDIR:
  # The name of the subdirectory of ufs-srweather-app where executables are
  # installed.
  #-----------------------------------------------------------------------
  #
  EXPT_BASEDIR: '' # This will be set in setup.py prior to extend_yaml() being called
  EXPT_SUBDIR: '{{ EXPT_SUBDIR }}'
  EXEC_SUBDIR: "exec"
  EXPTDIR: '{{ [workflow.EXPT_BASEDIR, workflow.EXPT_SUBDIR]|path_join }}'
  #
  #-----------------------------------------------------------------------
  #
  # Set the separator character(s) to use in the names of the grid, mosaic,
  # and orography fixed files.
  #
  # Ideally, the same separator should be used in the names of these fixed
  # files as the surface climatology fixed files (which always use a "."
  # as the separator), i.e. ideally, DOT_OR_USCORE should be set to "."
  #
  #-----------------------------------------------------------------------
  #
  DOT_OR_USCORE: "_"
  #
  #-----------------------------------------------------------------------
  #
  # Set file names.  Definitions:
  #
  # EXPT_CONFIG_FN:
  # Name of the user-specified configuration file for the forecast experiment.
  #
  # CONSTANTS_FN:
  # Name of the file containing definitions of various mathematical, physical, 
  # and SRW App contants.
  #
  # RGNL_GRID_NML_FN:
  # Name of file containing the namelist settings for the code that generates
  # a "ESGgrid" type of regional grid.
  #
  # FV3_NML_BASE_SUITE_FN:
  # Name of Fortran namelist file containing the forecast model's base suite
  # namelist, i.e. the portion of the namelist that is common to all physics
  # suites.
  #
  # FV3_NML_YAML_CONFIG_FN:
  # Name of YAML configuration file containing the forecast model's namelist
  # settings for various physics suites.
  #
  # FV3_NML_BASE_ENS_FN:
  # Name of Fortran namelist file containing the forecast model's base 
  # ensemble namelist, i.e. the the namelist file that is the starting point 
  # from which the namelist files for each of the enesemble members are
  # generated.
  #
  # FV3_EXEC_FN:
  # Name to use for the forecast model executable when it is copied from
  # the directory in which it is created in the build step to the executables
  # directory (EXECDIR; this is set during experiment generation).
  #
  # DIAG_TABLE_TMPL_FN:
  # Name of a template file that specifies the output fields of the
  # forecast model (ufs-weather-model: diag_table) followed by the name
  # of the ccpp_phys_suite.  Its default value is the name of the file
  # that the ufs weather model 
  # expects to read in.
  #
  # FIELD_TABLE_TMPL_FN:
  # Name of a template file that specifies the tracers in IC/LBC files of the 
  # forecast model (ufs-weather-mode: field_table) followed by [dot_ccpp_phys_suite]. 
  # Its default value is the name of the file that the ufs weather model expects 
  # to read in.
  #
  # MODEL_CONFIG_TMPL_FN:
  # Name of a template file that contains settings and configurations for the 
  # NUOPC/ESMF main component (ufs-weather-model: model_config). Its default 
  # value is the name of the file that the ufs weather model expects to read in.
  #
  # NEMS_CONFIG_TMPL_FN:
  # Name of a template file that contains information about the various NEMS 
  # components and their run sequence (ufs-weather-model: nems.configure). 
  # Its default value is the name of the file that the ufs weather model expects 
  # to read in.
  #
  # AQM_RC_TMPL_FN:
  # Template file name of resource file for NOAA Air Quality Model (AQM)
  #
  # FCST_MODEL:
  # Name of forecast model (default=ufs-weather-model)
  #
  # WFLOW_XML_FN:
  # Name of the rocoto workflow XML file that the experiment generation
  # script creates and that defines the workflow for the experiment.
  #
  # GLOBAL_VAR_DEFNS_FN:
  # Name of file (a shell script) containing the defintions of the primary 
  # experiment variables (parameters) defined in this default configuration 
  # script and in the user-specified configuration as well as secondary 
  # experiment variables generated by the experiment generation script.  
  # This file is sourced by many scripts (e.g. the J-job scripts corresponding 
  # to each workflow task) in order to make all the experiment variables 
  # available in those scripts.
  #
  # EXTRN_MDL_VAR_DEFNS_FN:
  # Name of file (a shell script) containing the defintions of variables
  # associated with the external model from which ICs or LBCs are generated.  This
  # file is created by the TN_GET_EXTRN_* task because the values of the variables
  # it contains are not known before this task runs.  The file is then sourced by
  # the TN_MAKE_ICS and TN_MAKE_LBCS tasks.
  #
  # WFLOW_LAUNCH_SCRIPT_FN:
  # Name of the script that can be used to (re)launch the experiment's rocoto
  # workflow.
  #
  # WFLOW_LAUNCH_LOG_FN:
  # Name of the log file that contains the output from successive calls to
  # the workflow launch script (WFLOW_LAUNCH_SCRIPT_FN).
  #
  #-----------------------------------------------------------------------
  #
  EXPT_CONFIG_FN: "config.yaml"
  CONSTANTS_FN: "constants.yaml"
  
  RGNL_GRID_NML_FN: "regional_grid.nml"
  
  FV3_NML_BASE_SUITE_FN: "input.nml.FV3"
  FV3_NML_YAML_CONFIG_FN: "FV3.input.yml"
  FV3_NML_BASE_ENS_FN: "input.nml.base_ens"
  FV3_NML_FN: "input.nml"
  FV3_EXEC_FN: "ufs_model"
  
  DATA_TABLE_FN: "data_table"
  DIAG_TABLE_FN: "diag_table"
  FIELD_TABLE_FN: "field_table"
  DIAG_TABLE_TMPL_FN: 'diag_table.{{ CCPP_PHYS_SUITE }}'
  FIELD_TABLE_TMPL_FN: 'field_table.{{ CCPP_PHYS_SUITE }}'
  MODEL_CONFIG_FN: "model_configure"
  NEMS_CONFIG_FN: "nems.configure"
  AQM_RC_FN: "aqm.rc"
  AQM_RC_TMPL_FN: "aqm.rc"

  FV3_NML_BASE_SUITE_FP: '{{ [user.PARMdir, FV3_NML_BASE_SUITE_FN]|path_join }}'
  FV3_NML_YAML_CONFIG_FP: '{{ [user.PARMdir, FV3_NML_YAML_CONFIG_FN]|path_join }}'
  FV3_NML_BASE_ENS_FP: '{{ [EXPTDIR, FV3_NML_BASE_ENS_FN]|path_join }}'
  DATA_TABLE_TMPL_FP: '{{ [user.PARMdir, DATA_TABLE_FN]|path_join }}'
  DIAG_TABLE_TMPL_FP: '{{ [user.PARMdir, DIAG_TABLE_TMPL_FN]|path_join }}'
  FIELD_TABLE_TMPL_FP: '{{ [user.PARMdir, FIELD_TABLE_TMPL_FN]|path_join }}'
  MODEL_CONFIG_TMPL_FP: '{{ [user.PARMdir, MODEL_CONFIG_FN]|path_join }}'
  NEMS_CONFIG_TMPL_FP: '{{ [user.PARMdir, NEMS_CONFIG_FN]|path_join }}'
  AQM_RC_TMPL_FP: '{{ [user.PARMdir, AQM_RC_TMPL_FN]|path_join }}'

  # These are staged in the exptdir at configuration time
  DATA_TABLE_FP: '{{ [EXPTDIR, DATA_TABLE_FN]|path_join }}'
  FIELD_TABLE_FP: '{{ [EXPTDIR, FIELD_TABLE_FN]|path_join }}'
  NEMS_CONFIG_FP: '{{ [EXPTDIR, NEMS_CONFIG_FN]|path_join }}'
  FV3_NML_FP: '{{ [EXPTDIR, FV3_NML_FN]|path_join }}'
  FV3_NML_FN: '{{ FV3_NML_BASE_SUITE_FN[:-4] }}'
  FV3_NML_CYCSFC_FP: '{{ [EXPTDIR, [FV3_NML_FN, "_cycsfc"]|join ]|path_join }}'
  FV3_NML_RESTART_FP: '{{ [EXPTDIR, [FV3_NML_FN, "_restart"]|join ]|path_join }}'
  FV3_NML_STOCH_FP: '{{ [EXPTDIR, [FV3_NML_FN, "_stoch"]|join ]|path_join }}'
  FV3_NML_RESTART_STOCH_FP: '{{ [EXPTDIR, [FV3_NML_FN, "_restart_stoch"]|join ]|path_join }}'

  FCST_MODEL: "ufs-weather-model"
  WFLOW_XML_FN: "FV3LAM_wflow.xml"
  GLOBAL_VAR_DEFNS_FN: "var_defns.sh"
  EXTRN_MDL_VAR_DEFNS_FN: "extrn_mdl_var_defns"
  WFLOW_LAUNCH_SCRIPT_FN: "launch_FV3LAM_wflow.sh"
  WFLOW_LAUNCH_LOG_FN: "log.launch_FV3LAM_wflow"

  GLOBAL_VAR_DEFNS_FP: '{{ [EXPTDIR, GLOBAL_VAR_DEFNS_FN] |path_join }}'
  WFLOW_LAUNCH_SCRIPT_FP: '{{ [user.USHdir, WFLOW_LAUNCH_SCRIPT_FN] |path_join }}'
  WFLOW_LAUNCH_LOG_FP: '{{ [EXPTDIR, WFLOW_LAUNCH_LOG_FN] |path_join }}'

  PYTHON_GRAPHICS_YML_FN: "rrfs_subset.yml"
  #
  #-----------------------------------------------------------------------
  #
  # Set the fix file paths
  #
  # FIXdir:
  # Location where fix files will be stored for a given experiment
  #
  # FIXam:
  # Directory containing the fixed files (or symlinks) for various fields on
  # global grids (which are usually much coarser than the native FV3-LAM grid).
  #
  # FIXclim:
  # Directory containing the MERRA2 aerosol climatology data file and
  # lookup tables for optics properties
  #
  # FIXlam:
  # Directory containing the fixed files (or symlinks) for the grid,
  # orography, and surface climatology on the native FV3-LAM grid.
  #
  # THOMPSON_MP_CLIMO_FN and _FP:
  # Name and path of file that contains aerosol climatology data. It can
  # be used to generate approximate versions of the aerosol fields
  # needed by Thompson microphysics.  This file will be used to
  # generate such approximate aerosol fields in the ICs and LBCs if
  # Thompson MP is included in the physics suite and if the exteranl
  # model for ICs or LBCs does not already provide these fields.
  #
  #-----------------------------------------------------------------------
  #
  FIXdir: '{{ [EXPTDIR, "fix"]|path_join if user.RUN_ENVIR == "community" else [user.HOMEdir, "fix"]|path_join }}'
  FIXam: '{{ [FIXdir, "fix_am"]|path_join }}'
  FIXclim: '{{ [FIXdir, "fix_clim"]|path_join }}'
  FIXlam: '{{ [FIXdir, "fix_lam"]|path_join }}'

  THOMPSON_MP_CLIMO_FN: "Thompson_MP_MONTHLY_CLIMO.nc"
  THOMPSON_MP_CLIMO_FP: '{{ [FIXam, THOMPSON_MP_CLIMO_FN]|path_join }}'
  #
  #-----------------------------------------------------------------------
  #
  # Set CCPP-associated parameters.  Definitions:
  #
  # CCPP_PHYS_SUITE:
  # The physics suite that will run using CCPP (Common Community Physics
  # Package).  The choice of physics suite determines the forecast model's 
  # namelist file, the diagnostics table file, the field table file, and 
  # the XML physics suite definition file that are staged in the experiment 
  # directory or the cycle directories under it.
  #
  # *_FN and *_FP variables set the name and paths to the suite
  # definition files used for the experiment
  #-----------------------------------------------------------------------
  #
  CCPP_PHYS_SUITE: "FV3_GFS_v16"
  CCPP_PHYS_SUITE_FN: 'suite_{{ CCPP_PHYS_SUITE }}.xml'
  CCPP_PHYS_SUITE_IN_CCPP_FP: '{{ [user.UFS_WTHR_MDL_DIR, "FV3", "ccpp", "suites", CCPP_PHYS_SUITE_FN] |path_join }}'
  CCPP_PHYS_SUITE_FP: '{{ [workflow.EXPTDIR, CCPP_PHYS_SUITE_FN]|path_join }}'
  #
  #-----------------------------------------------------------------------
  #
  # Set the field dictionary file name and paths.
  #
  #-----------------------------------------------------------------------
  #
  FIELD_DICT_FN: "fd_nems.yaml"
  FIELD_DICT_IN_UWM_FP: '{{ [user.UFS_WTHR_MDL_DIR, "tests", "parm", FIELD_DICT_FN]|path_join }}'
  FIELD_DICT_FP: '{{ [workflow.EXPTDIR, FIELD_DICT_FN]|path_join }}'
  #
  #-----------------------------------------------------------------------
  #
  # Set GRID_GEN_METHOD.  This variable specifies the method to use to 
  # generate a regional grid in the horizontal.  The values that it can 
  # take on are:
  #
  # * "GFDLgrid":
  #   This setting will generate a regional grid by first generating a 
  #   "parent" global cubed-sphere grid and then taking a portion of tile
  #   6 of that global grid -- referred to in the grid generation scripts
  #   as "tile 7" even though it doesn't correspond to a complete tile --
  #   and using it as the regional grid.  Note that the forecast is run on
  #   only on the regional grid (i.e. tile 7, not tiles 1 through 6).
  #
  # * "ESGgrid":
  #   This will generate a regional grid using the map projection developed
  #   by Jim Purser of EMC.
  #
  # Note that:
  #
  # 1) If the experiment is using one of the predefined grids (i.e. if 
  #    PREDEF_GRID_NAME is set to the name of one of the valid predefined 
  #    grids), then GRID_GEN_METHOD will be reset to the value of 
  #    GRID_GEN_METHOD for that grid.  This will happen regardless of 
  #    whether or not GRID_GEN_METHOD is assigned a value in the user-
  #    specified experiment configuration file, i.e. any value it may be
  #    assigned in the experiment configuration file will be overwritten.
  #
  # 2) If the experiment is not using one of the predefined grids (i.e. if 
  #    PREDEF_GRID_NAME is set to a null string), then GRID_GEN_METHOD must 
  #    be set in the experiment configuration file.  Otherwise, it will 
  #    remain set to a null string, and the experiment generation will 
  #    fail because the generation scripts check to ensure that it is set 
  #    to a non-empty string before creating the experiment directory.
  #
  #-----------------------------------------------------------------------
  #
  GRID_GEN_METHOD: ""
  #
  #-----------------------------------------------------------------------
  #
  # Set PREDEF_GRID_NAME.  This parameter specifies a predefined regional
  # grid, as follows:
  #
  # * If PREDEF_GRID_NAME is set to a valid predefined grid name, the grid 
  #   generation method GRID_GEN_METHOD, the (native) grid parameters, and 
  #   the write-component grid parameters are set to predefined values for 
  #   the specified grid, overwriting any settings of these parameters in 
  #   the user-specified experiment configuration file.  In addition, if 
  #   the time step DT_ATMOS and the computational parameters LAYOUT_X, 
  #   LAYOUT_Y, and BLOCKSIZE are not specified in that configuration file, 
  #   they are also set to predefined values for the specified grid.
  #
  # * If PREDEF_GRID_NAME is set to an empty string, it implies the user
  #   is providing the native grid parameters in the user-specified 
  #   experiment configuration file (EXPT_CONFIG_FN).  In this case, the 
  #   grid generation method GRID_GEN_METHOD, the native grid parameters, 
  #   and the write-component grid parameters as well as the time step 
  #   forecast model's main time step DT_ATMOS and the computational 
  #   parameters LAYOUT_X, LAYOUT_Y, and BLOCKSIZE must be set in that 
  #   configuration file; otherwise, the values of all of these parameters 
  #   in this default experiment configuration file will be used.
  #
  # Setting PREDEF_GRID_NAME provides a convenient method of specifying a
  # commonly used set of grid-dependent parameters.  The predefined grid 
  # parameters are specified in the script 
  #
  #   $HOMEdir/ush/set_predef_grid_params.py
  #
  #-----------------------------------------------------------------------
  #
  PREDEF_GRID_NAME: ""
  #
  #-----------------------------------------------------------------------
  #
  # Set forecast parameters.  Definitions:
  #
  # DATE_FIRST_CYCL:
  # Starting cycle date of the FIRST forecast in the set of forecasts to
  # run.  Format is "YYYYMMDDHH". Note: This has recently changed to
  # include the first cycle hour.
  #
  # DATE_LAST_CYCL:
  # Starting cylce date of the LAST forecast in the set of forecasts to run.
  # Format is "YYYYMMDDHH".  Note: This has recently changed to include
  # the last cycle hour.
  #
  # INCR_CYCL_FREQ:
  # Increment in hours for Rocoto cycle frequency.
  # Default is 24, which means cycle_freq=24:00:00
  #
  # FCST_LEN_HRS:
  # The length of each forecast, in integer hours.
  #
  # STARTYEAR,STARTMONTH,STARTDAY,STARTHOUR:
  # Year,month,day and hour of the first cycle in the set of forecasts to run
  # ENDYEAR,ENDMONTH,ENDDAY,ENDHOUR
  # Year,month,day and hour of the last cycle in the set of forecasts to run
  #
  # CYCL_HRS:
  # An array containing the hours of the day at which to launch forecasts.
  # Forecasts are launched at these hours on each day from DATE_FIRST_CYCL
  # to DATE_LAST_CYCL, inclusive.  Each element of this array must be a 
  # two-digit string representing an integer that is less than or equal to
  # 23, e.g. "00", "03", "12", "23".
  #
  # CYCL_HRS_SPINSTART:
  # An array containing the hours of the day at which the spin up cycle starts.
  #
  # CYCL_HRS_PRODSTART:
  # An array containing the hours of the day at which the product cycle starts,
  # from cold start input or from spin-up cycle forcast
  #
  # CYCL_HRS_PRODSTART_ENS:
  # An array containing the hours of the day at which the product cycle starts,
  # from cold start input or from spin-up cycle forcast, for the ensemble.
  # this is only needed for locating the RRFS ensemble files for the the deterministic hybrid analysis.
  #
  # CYCL_HRS_RECENTER:
  # An array containing the hours of the day at which the ensemble recenter is on
  #
  # CYCL_HRS_STOCH
  # An array containing the hours of the day at which the stochastics physcis is on
  # this might include: SPPT, SHUM, SKEB, SPP, LSM_SPP
  #
  # BOUNDARY_LEN_HRS
  # The length of boundary condition for normal forecast, in integer hours.
  #
  # BOUNDARY_LONG_LEN_HRS
  # The length of boundary condition for long forecast, in integer hours.
  #
  # BOUNDARY_PROC_GROUP_NUM
  # The number of groups used to run make_lbcs, in integer from 1 to forecast longest hours.
  #
  # FCST_LEN_HRS_SPINUP:
  # The length of each forecast in spin up cycles, in integer hours.
  #
  # FCST_LEN_HRS_CYCLES:
  # The length of forecast for each cycle, in integer hours.
  # When it empty, all forecast will be FCST_LEN_HRS
  #
  # DA_CYCLE_INTERV:
  # Data assimilation cycle interval, in integer hours for now.
  #
  # RESTART_INTERVAL:
  # frequency of the output restart files (unit:hour). 
  # Default=0: restart files are produced at the end of a forecast run
  # For example, i) RESTART_INTERVAL: 1 -1 => restart files are produced 
  # every hour with the prefix "YYYYMMDD.HHmmSS." in the RESTART directory
  # ii) RESTART_INTERVAL: 1 2 5 => restart files are produced only when 
  # fh = 1, 2, and 5.
  #
  #
  # RESTART_INTERVAL_LONG:
  # Set up frequenency or list of the forecast hours that FV3 should
  # generate the restart files.
  #
  # POSTPROC_LEN_HRS:
  # The length of post process, in integer hours.
  #
  # POSTPROC_LONG_LEN_HRS:
  # The length of long post process, in integer hours.
  #
  # CYCL_HRS_HYB_FV3LAM_ENS:
  # An array containing the hours of the day at which the GSI hybrid using FV3LAM ensemeble.
  #
  # FCST_LEN_CYCL:
  # The length of forecast for each cycle date in integer hours.
  # This is valid only when FCST_LEN_HRS = -1.
  # This pattern is recurred for all cycle dates.
  #
  #-----------------------------------------------------------------------
  #
  DATE_FIRST_CYCL: "YYYYMMDDHH"
  DATE_LAST_CYCL: "YYYYMMDDHH"
  INCR_CYCL_FREQ: 24
  FCST_LEN_HRS: 24
  FCST_LEN_CYCL:
    - 6
    - 12
    - 12
    - 6
  STARTYEAR: "YYYY"
  STARTMONTH: "MM"
  STARTDAY: "DD"
  STARTHOUR: "HH"
  ENDYEAR: "YYYY"
  ENDMONTH: "MM"
  ENDDAY: "DD"
  ENDHOUR: "HH"
  CYCL_HRS: []
  CYCL_HRS_SPINSTART: []
  CYCL_HRS_PRODSTART: []
  CYCL_HRS_PRODSTART_ENS: []
  CYCL_HRS_RECENTER: []
  CYCL_HRS_STOCH: []
  BOUNDARY_LEN_HRS: 0
  BOUNDARY_LONG_LEN_HRS: 0
  BOUNDARY_PROC_GROUP_NUM: 1
  POSTPROC_LEN_HRS: 1
  POSTPROC_LONG_LEN_HRS: 1
  FCST_LEN_HRS_SPINUP: 1
  FCST_LEN_HRS_CYCLES: []
  DA_CYCLE_INTERV: 3
  RESTART_INTERVAL: 0 # was 3,6 in rrfs_dev
  RESTART_INTERVAL_LONG: 0 # was 3.6 in rrfs_dev
  CYCL_HRS_HYB_FV3LAM_ENS: [ "99" ]
  #
  #-----------------------------------------------------------------------
  #
  # Set PREEXISTING_DIR_METHOD.  This variable determines the method to use
  # use to deal with preexisting directories [e.g ones generated by previous
  # calls to the experiment generation script using the same experiment name
  # (EXPT_SUBDIR) as the current experiment].  This variable must be set to
  # one of "delete", "upgrade", "rename", and "quit".  The resulting behavior for each
  # of these values is as follows:
  #
  # * "delete":
  #   The preexisting directory is deleted and a new directory (having the
  #   same name as the original preexisting directory) is created.
  #
  # * "upgrade":
  #    save a copy and then upgrade the preexisting $EXPDIR directory
  #    keep intact for other preexisting directories
  #
  # * "rename":
  #   The preexisting directory is renamed and a new directory (having the
  #   same name as the original preexisting directory) is created.  The new
  #   name of the preexisting directory consists of its original name and
  #   the suffix "_oldNNN", where NNN is a 3-digit integer chosen to make
  #   the new name unique.
  #
  # * "quit":
  #   The preexisting directory is left unchanged, but execution of the
  #   currently running script is terminated.  In this case, the preexisting
  #   directory must be dealt with manually before rerunning the script.
  #
  #-----------------------------------------------------------------------
  #
  PREEXISTING_DIR_METHOD: "delete"
  #
  #-----------------------------------------------------------------------
  #
  # Set flags for more detailed messages.  Defintitions:
  #
  # VERBOSE:
  # This is a flag that determines whether or not the experiment generation 
  # and workflow task scripts tend to print out more informational messages.
  #
  # DEBUG:
  # This is a flag that determines whether or not very detailed debugging
  # messages are printed to out.  Note that if DEBUG is set to TRUE, then
  # VERBOSE will also get reset to TRUE if it isn't already.
  #
  # SAVE_CYCLE_LOG:
  # This is a flag that determines whether or not save
  # the information related to data assimilation cycling, such as background
  # used in each cycle
  #
  #-----------------------------------------------------------------------
  #
  VERBOSE: true
  DEBUG: false
  SAVE_CYCLE_LOG: true

  #-----------------------------------------------------------------------
  #
  # COMPILER:
  # Type of compiler invoked during the build step. Currently, this must 
  # be set manually; it is not inherited from the build system in the 
  # ufs-srweather-app directory.
  #
  # SYMLINK_FIX_FILES:
  # Symlink fix files to experiment directory if true; otherwise copy the files.
  #
  # GET_OBS:
  # Task modulefile name for all get_obs_* tasks
  #
  # TN_VX:
  # Task name to use in forming the modulefile name for all verification
  # tasks.
  #
  #------------------------------------------------------------------------
  #
  COMPILER: "intel"
  SYMLINK_FIX_FILES: true

  GET_OBS: "get_obs"
  TN_VX: "run_vx"
  #
  #-----------------------------------------------------------------------
  #
  # DO_REAL_TIME:
  # switch for real-time run
  #
  #-----------------------------------------------------------------------
  #
  DO_REAL_TIME: false
  #
  #-----------------------------------------------------------------------
  #
  # COLDSTART:
  # Flag turning on/off warm start
  #
  # WARMSTART_CYCLE_DIR:
  # Path to the directory where RESTART dir is located for warm start
  #
  #-----------------------------------------------------------------------
  #
  COLDSTART: true
  WARMSTART_CYCLE_DIR: "/path/to/warm/start/cycle/dir"

#----------------------------
# WORKFLOW SWITCHES config parameters
#-----------------------------
workflow_switches:
  #
  #-----------------------------------------------------------------------
  #
  # Set flags (and related directories) that determine whether various
  # workflow tasks should be run.  Note that the TN_MAKE_GRID, TN_MAKE_OROG, 
  # and TN_MAKE_SFC_CLIMO are all cycle-independent tasks, i.e. if they 
  # are to be run, they do so only once at the beginning of the workflow 
  # before any cycles are run.  Definitions:
  #
  # RUN_TASK_MAKE_GRID:
  # Flag that determines whether the TN_MAKE_GRID task is to be run.  If 
  # this is set to true, the grid generation task is run and new grid
  # files are generated.  If it is set to false, then the scripts look
  # for pregenerated grid files in the directory specified by GRID_DIR 
  # (see below).
  #
  # RUN_TASK_MAKE_OROG:
  # Same as RUN_TASK_MAKE_GRID but for the TN_MAKE_OROG task.
  #
  # RUN_TASK_MAKE_SFC_CLIMO:
  # Same as RUN_TASK_MAKE_GRID but for the TN_MAKE_SFC_CLIMO task.
  #
  # RUN_TASK_GET_EXTRN_ICS:
  # Flag that determines whether the TN_GET_EXTRN_ICS task is to be run.
  #
  # RUN_TASK_GET_EXTRN_LBCS:
  # Flag that determines whether the TN_GET_EXTRN_LBCS task is to be run.
  #
  # RUN_TASK_MAKE_ICS:
  # Flag that determines whether the TN_MAKE_ICS task is to be run.
  #
  # RUN_TASK_MAKE_LBCS:
  # Flag that determines whether the TN_MAKE_LBCS task is to be run.
  #
  # RUN_TASK_RUN_FCST:
  # Flag that determines whether the TN_RUN_FCST task is to be run.
  #
  # RUN_TASK_RUN_POST:
  # Flag that determines whether the TN_RUN_POST task is to be run.
  # 
  # RUN_TASK_GET_OBS_CCPA:
  # Flag that determines whether to run the TN_GET_OBS_CCPA task, which
  # retrieves the CCPA hourly precipitation files used by METplus from NOAA HPSS. 
  # 
  # RUN_TASK_GET_OBS_MRMS:
  # Flag that determines whether to run the TN_GET_OBS_MRMS task, which
  # retrieves the MRMS composite reflectivity files used by METplus from NOAA HPSS. 
  #
  # RUN_TASK_GET_OBS_NDAS:
  # Flag that determines whether to run the TN_GET_OBS_NDAS task, which
  # retrieves the NDAS PrepBufr files used by METplus from NOAA HPSS. 
  #
  # RUN_TASK_VX_GRIDSTAT:
  # Flag that determines whether the grid-stat verification task is to be
  # run.
  #
  # RUN_TASK_VX_POINTSTAT:
  # Flag that determines whether the point-stat verification task is to be
  # run.
  #
  # RUN_TASK_VX_ENSGRID:
  # Flag that determines whether the ensemble-stat verification for gridded
  # data task is to be run. 
  #
  # RUN_TASK_VX_ENSPOINT:
  # Flag that determines whether the ensemble point verification task is
  # to be run. If this flag is set, both ensemble-stat point verification
  # and point verification of ensemble-stat output is computed.
  #
  # RUN_TASK_PLOT_ALLVARS:
  # Flag that determines whether to run python plotting scripts
  #
  # RUN_TASK_AQM_ICS:
  # Flag that determines whether the TN_AQM_ICS task is to be run for air quality modeling.
  #
  # RUN_TASK_AQM_LBCS:
  # Flag that determines whether the TN_AQM_LBCS task is to be run for air quality modeling.
  #
  # RUN_TASK_NEXUS_GFS_SFC:
  # Flag that determines whether the TN_NEXUS_GFS_SFC task is to be run for air quality modeling.
  #
  # RUN_TASK_NEXUS_EMISSION:
  # Flag that determines whether the TN_NEXUS_EMISSION task is to be run for air quality modeling.
  #
  # RUN_TASK_FIRE_EMISSION:
  # Flag that determines whether the TN_FIRE_EMISSION task is to be run for air quality modeling.
  #
  # RUN_TASK_POINT_SOURCE:
  # Flag that determines whether the TN_POINT_SOURCE task is to be run for air quality modeling.
  #
  # RUN_TASK_PRE_POST_STAT:
  # Flag that determines whether the TN_PRE_POST_STAT task is to be run for air quality modeling.
  #
  # RUN_TASK_POST_STAT_O3:
  # Flag that determines whether the TN_POST_STAT_O3 task is to be run for air quality modeling.
  #
  # RUN_TASK_POST_STAT_PM25:
  # Flag that determines whether the TN_POST_STAT_PM25 task is to be run for air quality modeling.
  #
  # RUN_TASK_BIAS_CORRECTION_O3:
  # Flag that determines whether the TN_BIAS_CORRECTION_O3 task is to be run for air quality modeling.
  #
  # RUN_TASK_BIAS_CORRECTION_PM25:
  # Flag that determines whether the TN_BIAS_CORRECTION_PM25 task is to be run for air quality modeling.
  #
  #-----------------------------------------------------------------------
  #
  RUN_TASK_MAKE_GRID: true
  RUN_TASK_MAKE_OROG: true
  RUN_TASK_MAKE_SFC_CLIMO: true
  
  RUN_TASK_GET_EXTRN_ICS: true
  RUN_TASK_GET_EXTRN_LBCS: true
  RUN_TASK_MAKE_ICS: true
  RUN_TASK_MAKE_LBCS: true
  RUN_TASK_RUN_FCST: true
  RUN_TASK_RUN_POST: true
  
  RUN_TASK_GET_OBS_CCPA: false
  RUN_TASK_GET_OBS_MRMS: false
  RUN_TASK_GET_OBS_NDAS: false
  RUN_TASK_VX_GRIDSTAT: false
  RUN_TASK_VX_POINTSTAT: false
  RUN_TASK_VX_ENSGRID: false
  RUN_TASK_VX_ENSPOINT: false

  RUN_TASK_PLOT_ALLVARS: false

  RUN_TASK_AQM_ICS: false
  RUN_TASK_AQM_LBCS: false
  RUN_TASK_NEXUS_GFS_SFC: false
  RUN_TASK_NEXUS_EMISSION: false
  RUN_TASK_FIRE_EMISSION: false
  RUN_TASK_POINT_SOURCE: false
  RUN_TASK_PRE_POST_STAT: false
  RUN_TASK_POST_STAT_O3: false
  RUN_TASK_POST_STAT_PM25: false
  RUN_TASK_BIAS_CORRECTION_O3: false
  RUN_TASK_BIAS_CORRECTION_PM25: false
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters associated with running retrospective experiments.  Definitions:
  #
  # DO_RRFS_DEV:
  # Flag to turn on RRFS dev workflow. Should be removed
  # in the future once SRW and RRFS dev workflows are completely integrated
  #
  # DO_RETRO:
  # Flag turn on the retrospective experiments.
  #
  # DO_SPINUP:
  # Flag turn on the spin-up cycle.
  #
  # DO_POST_SPINUP:
  # Flag turn on the UPP for spin-up cycle.
  #
  # DO_POST_PROD:
  # Flag turn on the UPP for prod cycle.
  #
  # DO_PARALLEL_PRDGEN:
  # Flag turn on parallel wgrib2 runs in prdgen .
  #
  #-----------------------------------------------------------------------
  #
  DO_RRFS_DEV: false # Turn this on to test RRFS dev workflow
  DO_RETRO: true # Turn this on temporarily
  DO_POST_PROD: false # Turn this off temporarily
  DO_SPINUP: false
  DO_POST_SPINUP: false
  DO_PARALLEL_PRDGEN: false
  #
  #-----------------------------------------------------------------------
  #
  # Set switches associated with ensembles.  Definitions:
  #
  # DO_ENSEMBLE:
  # Flag that determines whether to run a set of ensemble forecasts (for
  # each set of specified cycles).  If this is set to true, NUM_ENS_MEMBERS
  # forecasts are run for each cycle, each with a different set of stochastic
  # seed values.  Otherwise, a single forecast is run for each cycle.
  #
  # DO_ENSCONTROL: 
  # In ensemble mode, whether or not to run member 1 as control member
  #
  # DO_GSIOBSERVER:
  # Decide whether or not to run GSI observer
  #
  # DO_ENKFUPDATE:
  # Decide whether or not to run EnKF update for the ensemble members
  #
  # DO_ENKF_RADAR_REF:
  # Decide whether or not to run Radar Reflectivity EnKF update for the ensemble members
  #
  # DO_ENVAR_RADAR_REF:
  # Decide whether or not to run Radar Reflectivity hybrid analysis
  #
  # DO_RECENTER:
  # Decide whether or not to run recenter for the ensemble members
  #
  # DO_SAVE_INPUT:
  # Decide whether or not to run save_input after the DA analysis  
  #
  # DO_ENS_GRAPHICS:
  # Flag to turn on/off ensemble graphics. Turns OFF deterministic
  # graphics.
  #
  # DO_ENSPOST:
  # Flag to turn on/off python ensemble postprocessing for WPC testbeds.
  #
  # DO_ENSINIT:
  # Decide whether or not to do ensemble initialization by running 1 timestep ensemble
  # forecast and recentering on the deterministic analysis
  #
  # DO_ENSFCST:
  # Flag that determines whether to run ensemble free forecasts (for
  # each set of specified cycles).  If this is set to "TRUE", NUM_ENS_MEMBERS_FCST
  # forecasts are run for each specified cycle, each with a different set of stochastic
  # seed values. 
  #
  #-----------------------------------------------------------------------
  #
  DO_ENSEMBLE: false
  DO_ENSFCST: false
  DO_ENSCONTROL: false
  DO_GSIOBSERVER: false
  DO_ENKFUPDATE: false
  DO_ENKF_RADAR_REF: false
  DO_ENVAR_RADAR_REF: false
  DO_RECENTER: false
  DO_ENS_GRAPHICS: false
  DO_ENSPOST: false
  DO_ENSINIT: false
  DO_SAVE_INPUT: false
  #
  #-----------------------------------------------------------------------
  #
  # Set switches associated with running data assimilation.  Definitions:
  #
  # DO_DACYCLE:
  # Flag that determines whether to run a data assimilation cycle.
  #
  # DO_SURFACE_CYCLE:
  # Flag that determines whether to continue cycle surface fields.
  #
  # DO_SOIL_ADJUST:
  # Flag that determines whether to adjust soil T and Q based on
  # the lowest level T/Q analysis increments.
  #
  # DO_UPDATE_BC:
  # Flag that determines whether to update boundary conditions based on the 
  # analysis results
  #
  # DO_RADDA:
  # Flag that determines whether to assimilate satellite radiance data
  #
  # DO_BUFRSND:
  # Decide whether or not to run EMC BUFR sounding
  #
  # DO_SMOKE_DUST
  # Flag turn on smoke and dust for RRFS-SD
  #
  #-----------------------------------------------------------------------
  #
  DO_DACYCLE: false
  DO_SURFACE_CYCLE: false
  DO_SOIL_ADJUST: false
  DO_UPDATE_BC: false
  DO_RADDA: false
  DO_BUFRSND: false
  DO_SMOKE_DUST: false
  #
  #-----------------------------------------------------------------------
  #
  # Parameters for JEDI options
  # DO_JEDI_ENVAR_IODA:
  #      Flag turn on the JEDI-IODA converters for EnVAR.  It requires GSI 
  #      to produce NetCDF diag files
  #-----------------------------------------------------------------------
  #
  DO_JEDI_ENVAR_IODA: false
  #
  #-----------------------------------------------------------------------
  #
  # Parameters for analysis options
  # DO_NONVAR_CLDANAL: 
  #     Flag turn on the non-var cloud analysis.
  # DO_REFL2TTEN: 
  #     Flag turn on the radar reflectivity to temperature tendenecy.
  # DO_NLDN_LGHT
  #     Flag turn on processing NLDN NetCDF lightning data
  #
  #-----------------------------------------------------------------------
  #
  DO_NONVAR_CLDANAL: false
  DO_REFL2TTEN: false
  DO_NLDN_LGHT: false
  DO_SMOKE_DUST: false
  #
  #-----------------------------------------------------------------------
  #
  # IS_RTMA:
  #   If true, some ICs,LBCs,GSI rocoto tasks will be turned off
  #
  #-----------------------------------------------------------------------
  #
  IS_RTMA: false

#----------------------------
# NCO specific variables
#-----------------------------
nco:
  #
  #-----------------------------------------------------------------------
  #
  # Set variables that are only used in NCO mode (i.e. when RUN_ENVIR is 
  # set to "nco").  Definitions:
  #
  # envir, NET, model_ver, RUN:
  # Standard environment variables defined in the NCEP Central Operations WCOSS
  # Implementation Standards document as follows:
  #
  #   envir:
  #   Set to "test" during the initial testing phase, "para" when running
  #   in parallel (on a schedule), and "prod" in production.
  #
  #   NET:
  #   Model name (first level of com directory structure)
  #
  #   model_ver:
  #   Version number of package in three digits (second level of com directory)
  #
  #   RUN:
  #   Name of model run (third level of com directory structure).
  #   In general, same as $NET
  #
  # OPSROOT:
  # The operations root directory in NCO mode.
  #
  # LOGBASEDIR:
  # Directory in which the log files from the workflow tasks will be placed.
  # 
  # NWGES:
  # The beginning portion of the directory that will contain the output 
  # files from the forecast for a given cycle.  For a cycle 
  # that starts on the date specified by yyyymmdd and hour specified by hh
  # (where yyyymmdd and hh are as described above), the directory in which
  # the forecast output files will be placed will be:
  #   $NWGES/$NET/$envir/$RUN.$yyyymmdd/$hh
  # 
  # For more information on NCO standards
  #   
  #   https://www.nco.ncep.noaa.gov/idsb/implementation_standards/ImplementationStandards.v11.0.0.pdf
  #
  #-----------------------------------------------------------------------
  #
  envir: "para"
  NET: "rrfs"
  RUN: "rrfs"
  model_ver: "v1.0.0"

  OPSROOT: '{{ workflow.EXPT_BASEDIR }}/../nco_dirs'
  COMROOT: '{{ OPSROOT }}/com'
  PACKAGEROOT: '{{ OPSROOT }}/packages'
  DATAROOT: '{{ OPSROOT }}/tmp'
  DCOMROOT: '{{ OPSROOT }}/dcom'
  LOGBASEDIR: '{{ OPSROOT }}/output'
  EXTROOT: '{{ OPSROOT }}/ext'
  COMIN_BASEDIR: '{{ COMROOT }}/{{ NET }}/{{ model_ver }}'
  COMOUT_BASEDIR: '{{ COMROOT }}/{{ NET }}/{{ model_ver }}'

  #
  # New additions from RRFS_dev1
  #
  NWGES: '{{ OPSROOT }}/nwges'
  NWGES_BASEDIR: '{{ NWGES }}'
  RRFSE_NWGES: '{{ OPSROOT }}/nwges'
  RRFSE_NWGES_BASEDIR: '{{ RRFSE_NWGES }}'
  ENSCTRL_NWGES: '{{ OPSROOT }}/nwges'
  ENSCTRL_NWGES_BASEDIR: '{{ ENSCTRL_NWGES}}'

  ENSCTRL_COMIN: '{{ COMIN_BASEDIR}}'
  ENSCTRL_COMOUT: '{{ COMOUT_BASEDIR}}'
  ENSCTRL_COMROOT: '{{ ENSCTRL_COMOUT }}'
  ENSCTRL_COMIN_BASEDIR: '{{ ENSCTRL_COMIN }}'
  ENSCTRL_COMOUT_BASEDIR: '{{ ENSCTRL_COMROOT}}/{{ envir}}'

  #
  #-----------------------------------------------------------------------
  #
  # FG_ROOTDIR:
  #  First Guess Root Directory, APP will find corresponding first guess
  #  fields from this directory. RRFS will find FG under NWGES_BASEDIR,
  #  but we needs to explicitly specify where to find FG for RTMA.
  #  So this parameter only matters for RTMA
  #
  #-----------------------------------------------------------------------
  #
  FG_ROOTDIR: ""

  #
  #-----------------------------------------------------------------------
  #
  # The following are also described in the NCO doc above
  #
  #-----------------------------------------------------------------------
  #
  DBNROOT: ""
  SENDECF: false
  SENDDBN: false
  SENDDBN_NTC: false
  SENDCOM: false
  SENDWEB: false
  KEEPDATA: true
  MAILTO: ""
  MAILCC: ""


#----------------------------------
# Start times for different setups
#----------------------------------
start_time:
  START_TIME_SPINUP: 01:10:00
  START_TIME_PROD: 02:20:00
  START_TIME_CONVENTIONAL_SPINUP: 00:40:00
  START_TIME_LATE_ANALYSIS: 01:40:00
  START_TIME_CONVENTIONAL: 00:40:00
  START_TIME_NSSLMOSIAC: 00:45:00
  START_TIME_LIGHTNINGNC: 00:45:00
  START_TIME_PROCSMOKE: 00:45:00

#----------------------------------
# Cycle definiton for each group
#----------------------------------
cycledefs:
  #-----------------------------------------------------------------------
  #
  # Set cycle definition for each group.  The cycle definition sets the cycle
  # time that the group will run. It has two way to set up:
  #  1) 00 HHs DDs MMs YYYYs *
  #       HHs can be "01-03/01" or "01,02,03" or "*"
  #       DDs,MMs can be "01-03" or "01,02,03" or "*"
  #       YYYYs can be "2020-2021" or "2020,2021" or "*"
  #  2)   start_time(YYYYMMDDHH00) end_time(YYYYMMDDHH00) interval(HH:MM:SS)
  #       for example: 202104010000 202104310000 12:00:00
  #  The default cycle definition is:
  #     "00 01 01 01 2100 *"
  #  which will likely never get to run.
  #
  # Definitions:
  #
  # AT_START_CYCLEDEF:
  # cycle definition for "at start" group
  # This group runs: make_grid, make_orog, make_sfc_climo
  #
  # INITIAL_CYCLEDEF:
  # cycle definition for "initial" group
  # This group runs get_extrn_ics, make_ics
  #
  # BOUNDARY_CYCLEDEF:
  # cycle definition for "boundary" group
  # This group runs: get_extrn_lbcs,make_lbcs
  #
  # BOUNDARY_LONG_CYCLEDEF:
  # cycle definition for "boundary_long" group
  # This group runs: get_extrn_lbcs_long,make_lbcs
  #
  # SPINUP_CYCLEDEF:
  # cycle definition for spin-up cycle group
  # This group runs: anal_gsi_input_spinup and data process, run_fcst_spinup, run_post_spinup
  #
  # PROD_CYCLEDEF:
  # cycle definition for product cycle group
  # This group runs: anal_gsi_input and data process, run_fcst, python_skewt, run_post, run_clean
  #
  # SAVEINPUT_CYCLEDEF:
  # cycle definition for saving INPUT files
  # This group runs: saveinput
  #
  # RECENTER_CYCLEDEF:
  # cycle definition for recenter cycle group
  # This group runs: recenter
  #
  # PRODLONG_CYCLEDEF:
  # same as PROD_CYCLEDEF, but for long forecast 
  #
  # ARCHIVE_CYCLEDEF:
  # cycle definition for "archive" group
  # This group runs: run_archive
  #
  #-----------------------------------------------------------------------
  #
  AT_START_CYCLEDEF: "00 01 01 01 2100 *"
  INITIAL_CYCLEDEF: "00 01 01 01 2100 *"
  BOUNDARY_CYCLEDEF: "00 01 01 01 2100 *"
  BOUNDARY_LONG_CYCLEDEF: "00 01 01 01 2100 *"
  SPINUP_CYCLEDEF: "00 01 01 01 2100 *"
  PROD_CYCLEDEF: "00 01 01 01 2100 *"
  PRODLONG_CYCLEDEF: "00 01 01 01 2100 *"
  RECENTER_CYCLEDEF: "00 01 01 01 2100 *"
  ARCHIVE_CYCLEDEF: "00 01 01 01 2100 *"
  SAVEINPUT_CYCLEDEF: "00 01 01 01 2100 *"

#----------------------------------
# GSI namelist parameters
#----------------------------------
gsi:
  #
  #-------------------------------------------------------------------------------------
  #      GSI Namelist parameters configurable across differnt applications
  # if we need to tune one GSI namelist parameter, we can elevate it to a shell variable
  # and assign value in config.sh and give it a default value in config_default.sh
  # In realtime testing, don't need to regenerate the whole workflow, you can tweak 
  # $EXPTDIR/var_defns.sh and $FIX_GSI/gsiparm.anl.sh to make sure the change is
  # expected and then put it back into config.sh and config_default.sh
  #       (need to follow FORTRAN namelist convetion)
  #-------------------------------------------------------------------------------------
  # &SETUP  and &BKGERR
  niter1: 50
  niter2: 50
  l_obsprvdiag: .false.
  diag_radardbz: .false.
  write_diag_2: .false.
  bkgerr_vs: 1.0
  bkgerr_hzscl: 0.7,1.4,2.80     #no trailing ,
  usenewgfsberror: .true.
  netcdf_diag: .false.
  binary_diag: .true.
  
  # &HYBRID_ENSEMBLE
  readin_localization: .true.     #if true, it overwrites the "beta1_inv/ens_h/ens_v" setting
  beta1_inv: 0.15                 #beata_inv is 1-ensemble_wgt
  ens_h: 110
  ens_v: 3
  regional_ensemble_option: 1     #1 for GDAS ; 5 for FV3LAM ensemble
  grid_ratio_fv3: 2.0             #fv3 resolution 3km, so analysis: 3*2: 6km
  grid_ratio_ens: 3               #if analysis is 3km, then ensemble: 3*3: 9km. GDAS ensemble is 20km
  i_en_perts_io: 1                #0 or 1: original file   3: pre-processed ensembles
  q_hyb_ens: .false.
  ens_fast_read: .false.
  
  # &RAPIDREFRESH_CLDSURF
  l_PBL_pseudo_SurfobsT: .false.
  l_PBL_pseudo_SurfobsQ: .false.
  i_use_2mQ4B: 0
  i_use_2mT4B: 0
  i_T_Q_adjust: 1
  l_rtma3d: .false.
  i_precip_vertical_check: 0
  #-----------------------------------------------------------------------
  # HYBENSMEM_NMIN:
  #    Minimum number of ensemble members required a hybrid GSI analysis 
  #-----------------------------------------------------------------------
  HYBENSMEM_NMIN: 80
  ANAVINFO_FN: "anavinfo.rrfs"
  ANAVINFO_DBZ_FN: "anavinfo.rrfs_dbz"
  ENKF_ANAVINFO_FN: "anavinfo.rrfs"
  ENKF_ANAVINFO_DBZ_FN: "anavinfo.enkf.rrfs_dbz"
  CONVINFO_FN: "convinfo.rrfs"
  BERROR_FN: "rap_berror_stats_global_RAP_tune" #under $FIX_GSI
  OBERROR_FN: "errtable.rrfs"
  HYBENSINFO_FN: "hybens_info.rrfs"
  #
  #-----------------------------------------------------------------------
  # default namelist for nonvar cloud analysis
  #-----------------------------------------------------------------------
  cld_bld_hgt: 1200.0
  l_precip_clear_only: .false.
  l_qnr_from_qr: .false.
  #
  #-----------------------------------------------------------------------
  # default weighting for control analysis in ensemble recentering
  #-----------------------------------------------------------------------
  beta_recenter: 1.0

#----------------------------
# MAKE GRID config parameters
#-----------------------------
task_make_grid:
  TN_MAKE_GRID: "make_grid"
  NNODES_MAKE_GRID: 1
  PPN_MAKE_GRID: 24
  WTIME_MAKE_GRID: 00:20:00
  MAXTRIES_MAKE_GRID: 2
  #
  #-----------------------------------------------------------------------
  #
  # GRID_DIR:
  # The directory in which to look for pregenerated grid files if 
  # RUN_TASK_MAKE_GRID is set to false.
  # 
  #-----------------------------------------------------------------------
  # 
  GRID_DIR: '{{ [workflow.EXPTDIR, "grid"]|path_join if workflow_switches.RUN_TASK_MAKE_GRID else "" }}'
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters specific to the "ESGgrid" method of generating a regional
  # grid (i.e. for GRID_GEN_METHOD set to "ESGgrid").  Definitions:
  #
  # ESGgrid_LON_CTR:
  # The longitude of the center of the grid (in degrees).
  #
  # ESGgrid_LAT_CTR:
  # The latitude of the center of the grid (in degrees).
  #
  # ESGgrid_DELX:
  # The cell size in the zonal direction of the regional grid (in meters).
  #
  # ESGgrid_DELY:
  # The cell size in the meridional direction of the regional grid (in 
  # meters).
  #
  # ESGgrid_NX:
  # The number of cells in the zonal direction on the regional grid.
  #
  # ESGgrid_NY:
  # The number of cells in the meridional direction on the regional grid.
  #
  # ESGgrid_WIDE_HALO_WIDTH:
  # The width (in units of number of grid cells) of the halo to add around
  # the regional grid before shaving the halo down to the width(s) expected
  # by the forecast model.  
  #
  # ESGgrid_PAZI:
  # The rotational parameter for the ESG grid (in degrees).
  #
  # In order to generate grid files containing halos that are 3-cell and
  # 4-cell wide and orography files with halos that are 0-cell and 3-cell
  # wide (all of which are required as inputs to the forecast model), the
  # grid and orography tasks first create files with halos around the regional
  # domain of width ESGgrid_WIDE_HALO_WIDTH cells.  These are first stored 
  # in files.  The files are then read in and "shaved" down to obtain grid
  # files with 3-cell-wide and 4-cell-wide halos and orography files with
  # 0-cell-wide (i.e. no halo) and 3-cell-wide halos.  For this reason, we
  # refer to the original halo that then gets shaved down as the "wide" 
  # halo, i.e. because it is wider than the 0-cell-wide, 3-cell-wide, and
  # 4-cell-wide halos that we will eventually end up with.  Note that the
  # grid and orography files with the wide halo are only needed as intermediates
  # in generating the files with 0-cell-, 3-cell-, and 4-cell-wide halos;
  # they are not needed by the forecast model.  
  # NOTE: Probably don't need to make ESGgrid_WIDE_HALO_WIDTH a user-specified 
  #       variable.  Just set it in the function set_gridparams_ESGgrid.py.
  #
  # Note that:
  #
  # 1) If the experiment is using one of the predefined grids (i.e. if 
  #    PREDEF_GRID_NAME is set to the name of one of the valid predefined
  #    grids), then:
  #
  #    a) If the value of GRID_GEN_METHOD for that grid is "GFDLgrid", then
  #       these parameters will not be used and thus do not need to be reset
  #       to non-empty strings.
  #
  #    b) If the value of GRID_GEN_METHOD for that grid is "ESGgrid", then
  #       these parameters will get reset to the values for that grid.  
  #       This will happen regardless of whether or not they are assigned 
  #       values in the user-specified experiment configuration file, i.e. 
  #       any values they may be assigned in the experiment configuration 
  #       file will be overwritten.
  #
  # 2) If the experiment is not using one of the predefined grids (i.e. if 
  #    PREDEF_GRID_NAME is set to a null string), then:
  #
  #    a) If GRID_GEN_METHOD is set to "GFDLgrid" in the user-specified 
  #       experiment configuration file, then these parameters will not be 
  #       used and thus do not need to be reset to non-empty strings.
  #
  #    b) If GRID_GEN_METHOD is set to "ESGgrid" in the user-specified 
  #       experiment configuration file, then these parameters must be set
  #       in that configuration file.
  #
  #-----------------------------------------------------------------------
  #
  ESGgrid_LON_CTR: ""
  ESGgrid_LAT_CTR: ""
  ESGgrid_DELX: ""
  ESGgrid_DELY: ""
  ESGgrid_NX: ""
  ESGgrid_NY: ""
  ESGgrid_WIDE_HALO_WIDTH: ""
  ESGgrid_PAZI: ""

  #-----------------------------------------------------------------------
  #
  # Set parameters specific to the "GFDLgrid" method of generating a regional
  # grid (i.e. for GRID_GEN_METHOD set to "GFDLgrid").  The following 
  # parameters will be used only if GRID_GEN_METHOD is set to "GFDLgrid". 
  # In this grid generation method:
  #
  # * The regional grid is defined with respect to a "parent" global cubed-
  #   sphere grid.  Thus, all the parameters for a global cubed-sphere grid
  #   must be specified in order to define this parent global grid even 
  #   though the model equations are not integrated on (they are integrated
  #   only on the regional grid).
  #
  # * GFDLgrid_NUM_CELLS is the number of grid cells in either one of the two 
  #   horizontal directions x and y on any one of the 6 tiles of the parent
  #   global cubed-sphere grid.  The mapping from GFDLgrid_NUM_CELLS to a nominal
  #   resolution (grid cell size) for a uniform global grid (i.e. Schmidt
  #   stretch factor GFDLgrid_STRETCH_FAC set to 1) for several values of
  #   GFDLgrid_NUM_CELLS is as follows:
  #
  #     GFDLgrid_NUM_CELLS      typical cell size
  #     ------------      -----------------
  #              192                  50 km
  #              384                  25 km
  #              768                  13 km
  #             1152                 8.5 km
  #             3072                 3.2 km
  #
  #   Note that these are only typical cell sizes.  The actual cell size on
  #   the global grid tiles varies somewhat as we move across a tile.
  #
  # * Tile 6 has arbitrarily been chosen as the tile to use to orient the
  #   global parent grid on the sphere (Earth).  This is done by specifying 
  #   GFDLgrid_LON_T6_CTR and GFDLgrid_LAT_T6_CTR, which are the longitude
  #   and latitude (in degrees) of the center of tile 6.
  #
  # * Setting the Schmidt stretching factor GFDLgrid_STRETCH_FAC to a value
  #   greater than 1 shrinks tile 6, while setting it to a value less than 
  #   1 (but still greater than 0) expands it.  The remaining 5 tiles change
  #   shape as necessary to maintain global coverage of the grid.
  #
  # * The cell size on a given global tile depends on both GFDLgrid_NUM_CELLS and
  #   GFDLgrid_STRETCH_FAC (since changing GFDLgrid_NUM_CELLS changes the number
  #   of cells in the tile, and changing GFDLgrid_STRETCH_FAC modifies the
  #   shape and size of the tile).
  #
  # * The regional grid is embedded within tile 6 (i.e. it doesn't extend
  #   beyond the boundary of tile 6).  Its exact location within tile 6 is
  #   is determined by specifying the starting and ending i and j indices
  #   of the regional grid on tile 6, where i is the grid index in the x
  #   direction and j is the grid index in the y direction.  These indices
  #   are stored in the variables 
  #
  #     GFDLgrid_ISTART_OF_RGNL_DOM_ON_T6G
  #     GFDLgrid_JSTART_OF_RGNL_DOM_ON_T6G
  #     GFDLgrid_IEND_OF_RGNL_DOM_ON_T6G
  #     GFDLgrid_JEND_OF_RGNL_DOM_ON_T6G
  #
  # * In the forecast model code and in the experiment generation and workflow
  #   scripts, for convenience the regional grid is denoted as "tile 7" even
  #   though it doesn't map back to one of the 6 faces of the cube from 
  #   which the parent global grid is generated (it maps back to only a 
  #   subregion on face 6 since it is wholly confined within tile 6).  Tile
  #   6 may be referred to as the "parent" tile of the regional grid.
  #
  # * GFDLgrid_REFINE_RATIO is the refinement ratio of the regional grid 
  #   (tile 7) with respect to the grid on its parent tile (tile 6), i.e.
  #   it is the number of grid cells along the boundary of the regional grid
  #   that abut one cell on tile 6.  Thus, the cell size on the regional 
  #   grid depends not only on GFDLgrid_NUM_CELLS and GFDLgrid_STRETCH_FAC (because
  #   the cell size on tile 6 depends on these two parameters) but also on 
  #   GFDLgrid_REFINE_RATIO.  Note that as on the tiles of the global grid, 
  #   the cell size on the regional grid is not uniform but varies as we 
  #   move across the grid.
  #
  # Definitions of parameters that need to be specified when GRID_GEN_METHOD
  # is set to "GFDLgrid":
  #
  # GFDLgrid_LON_T6_CTR:
  # Longitude of the center of tile 6 (in degrees).
  #
  # GFDLgrid_LAT_T6_CTR:
  # Latitude of the center of tile 6 (in degrees).
  #
  # GFDLgrid_NUM_CELLS:
  # Number of points in each of the two horizontal directions (x and y) on
  # each tile of the parent global grid.  Note that the name of this parameter
  # is really a misnomer because although it has the string "RES" (for 
  # "resolution") in its name, it specifies number of grid cells, not grid
  # size (in say meters or kilometers).  However, we keep this name in order
  # to remain consistent with the usage of the word "resolution" in the 
  # global forecast model and other auxiliary codes.
  #
  # GFDLgrid_STRETCH_FAC:
  # Stretching factor used in the Schmidt transformation applied to the
  # parent cubed-sphere grid.
  #
  # GFDLgrid_REFINE_RATIO:
  # Cell refinement ratio for the regional grid, i.e. the number of cells
  # in either the x or y direction on the regional grid (tile 7) that abut
  # one cell on its parent tile (tile 6).
  #
  # GFDLgrid_ISTART_OF_RGNL_DOM_ON_T6G:
  # i-index on tile 6 at which the regional grid (tile 7) starts.
  #
  # GFDLgrid_IEND_OF_RGNL_DOM_ON_T6G:
  # i-index on tile 6 at which the regional grid (tile 7) ends.
  #
  # GFDLgrid_JSTART_OF_RGNL_DOM_ON_T6G:
  # j-index on tile 6 at which the regional grid (tile 7) starts.
  #
  # GFDLgrid_JEND_OF_RGNL_DOM_ON_T6G:
  # j-index on tile 6 at which the regional grid (tile 7) ends.
  #
  # GFDLgrid_USE_NUM_CELLS_IN_FILENAMES:
  # Flag that determines the file naming convention to use for grid, orography,
  # and surface climatology files (or, if using pregenerated files, the
  # naming convention that was used to name these files).  These files 
  # usually start with the string "C${RES}_", where RES is an integer.
  # In the global forecast model, RES is the number of points in each of
  # the two horizontal directions (x and y) on each tile of the global grid
  # (defined here as GFDLgrid_NUM_CELLS).  If this flag is set to true, RES will
  # be set to GFDLgrid_NUM_CELLS just as in the global forecast model.  If it is
  # set to false, we calculate (in the grid generation task) an "equivalent
  # global uniform cubed-sphere resolution" -- call it RES_EQUIV -- and 
  # then set RES equal to it.  RES_EQUIV is the number of grid points in 
  # each of the x and y directions on each tile that a global UNIFORM (i.e. 
  # stretch factor of 1) cubed-sphere grid would have to have in order to
  # have the same average grid size as the regional grid.  This is a more
  # useful indicator of the grid size because it takes into account the 
  # effects of GFDLgrid_NUM_CELLS, GFDLgrid_STRETCH_FAC, and GFDLgrid_REFINE_RATIO
  # in determining the regional grid's typical grid size, whereas simply
  # setting RES to GFDLgrid_NUM_CELLS doesn't take into account the effects of
  # GFDLgrid_STRETCH_FAC and GFDLgrid_REFINE_RATIO on the regional grid's
  # resolution.  Nevertheless, some users still prefer to use GFDLgrid_NUM_CELLS
  # in the file names, so we allow for that here by setting this flag to
  # true.
  #
  # Note that:
  #
  # 1) If the experiment is using one of the predefined grids (i.e. if 
  #    PREDEF_GRID_NAME is set to the name of one of the valid predefined
  #    grids), then:
  #
  #    a) If the value of GRID_GEN_METHOD for that grid is "GFDLgrid", then
  #       these parameters will get reset to the values for that grid.  
  #       This will happen regardless of whether or not they are assigned 
  #       values in the user-specified experiment configuration file, i.e. 
  #       any values they may be assigned in the experiment configuration 
  #       file will be overwritten.
  #
  #    b) If the value of GRID_GEN_METHOD for that grid is "ESGgrid", then
  #       these parameters will not be used and thus do not need to be reset
  #       to non-empty strings.
  #
  # 2) If the experiment is not using one of the predefined grids (i.e. if 
  #    PREDEF_GRID_NAME is set to a null string), then:
  #
  #    a) If GRID_GEN_METHOD is set to "GFDLgrid" in the user-specified 
  #       experiment configuration file, then these parameters must be set
  #       in that configuration file.
  #
  #    b) If GRID_GEN_METHOD is set to "ESGgrid" in the user-specified 
  #       experiment configuration file, then these parameters will not be 
  #       used and thus do not need to be reset to non-empty strings.
  #
  #-----------------------------------------------------------------------
  #
  GFDLgrid_LON_T6_CTR: ""
  GFDLgrid_LAT_T6_CTR: ""
  GFDLgrid_NUM_CELLS: ""
  GFDLgrid_STRETCH_FAC: ""
  GFDLgrid_REFINE_RATIO: ""
  GFDLgrid_ISTART_OF_RGNL_DOM_ON_T6G: ""
  GFDLgrid_IEND_OF_RGNL_DOM_ON_T6G: ""
  GFDLgrid_JSTART_OF_RGNL_DOM_ON_T6G: ""
  GFDLgrid_JEND_OF_RGNL_DOM_ON_T6G: ""
  GFDLgrid_USE_NUM_CELLS_IN_FILENAMES: ""
  #
#----------------------------
# MAKE OROG config parameters
#-----------------------------
task_make_orog:
  TN_MAKE_OROG: "make_orog"
  NNODES_MAKE_OROG: 1
  PPN_MAKE_OROG: 24
  WTIME_MAKE_OROG: 00:20:00
  MAXTRIES_MAKE_OROG: 2
  KMP_AFFINITY_MAKE_OROG: "disabled"
  OMP_NUM_THREADS_MAKE_OROG: 6
  OMP_STACKSIZE_MAKE_OROG: "2048m"
  OROG_DIR: '{{ [workflow.EXPTDIR, "orog"]|path_join if workflow_switches.RUN_TASK_MAKE_OROG else "" }}'

#----------------------------
# MAKE SFC CLIMO config parameters
#-----------------------------
task_make_sfc_climo:
  TN_MAKE_SFC_CLIMO: "make_sfc_climo"
  NNODES_MAKE_SFC_CLIMO: 2
  PPN_MAKE_SFC_CLIMO: 24
  WTIME_MAKE_SFC_CLIMO: 00:20:00
  MAXTRIES_MAKE_SFC_CLIMO: 2
  KMP_AFFINITY_MAKE_SFC_CLIMO: "scatter"
  OMP_NUM_THREADS_MAKE_SFC_CLIMO: 1
  OMP_STACKSIZE_MAKE_SFC_CLIMO: "1024m"
  SFC_CLIMO_DIR: '{{ [workflow.EXPTDIR, "sfc_climo"]|path_join if workflow_switches.RUN_TASK_MAKE_SFC_CLIMO else "" }}'

#----------------------------
# EXTRN ICS config parameters
#-----------------------------
task_get_extrn_ics:
  TN_GET_EXTRN_ICS: "get_extrn_ics"
  NNODES_GET_EXTRN_ICS: 1
  PPN_GET_EXTRN_ICS: 1
  MEM_GET_EXTRN_ICS: 2G
  WTIME_GET_EXTRN_ICS: 00:45:00
  MAXTRIES_GET_EXTRN_ICS: 1
  #
  #-----------------------------------------------------------------------
  #
  # Set initial and lateral boundary condition generation parameters.  
  # Definitions:
  #
  # EXTRN_MDL_NAME_ICS:
  #`The name of the external model that will provide fields from which 
  # initial condition (including and surface) files will be generated for
  # input into the forecast model.
  #
  # EXTRN_MDL_ICS_OFFSET_HRS:
  # Users may wish to start a forecast from a forecast of a previous cycle
  # of an external model. This variable sets the number of hours earlier
  # the external model started than when the FV3 forecast configured here
  # should start. For example, the forecast should start from a 6 hour
  # forecast of the GFS, then EXTRN_MDL_ICS_OFFSET_HRS=6.
  #
  # FV3GFS_FILE_FMT_ICS:
  # If using the FV3GFS model as the source of the ICs (i.e. if EXTRN_MDL_NAME_ICS
  # is set to "FV3GFS"), this variable specifies the format of the model
  # files to use when generating the ICs.
  #
  #-----------------------------------------------------------------------
  #
  EXTRN_MDL_NAME_ICS: "FV3GFS"
  EXTRN_MDL_ICS_OFFSET_HRS: 0
  FV3GFS_FILE_FMT_ICS: "nemsio"
  #
  #-----------------------------------------------------------------------
  #
  # Base directories in which to search for external model files.
  #
  # EXTRN_MDL_SYSBASEDIR_ICS:
  # Base directory on the local machine containing external model files for
  # generating ICs on the native grid.  The way the full path containing 
  # these files is constructed depends on the user-specified external model
  # for ICs, i.e. EXTRN_MDL_NAME_ICS.
  #
  # Note that this must be defined as a null string here so that if it is 
  # specified by the user in the experiment configuration file, it remains 
  # set to those values, and if not, it gets set to machine-dependent 
  # values.
  #
  #-----------------------------------------------------------------------
  # 
  EXTRN_MDL_SYSBASEDIR_ICS: ''
  #
  #-----------------------------------------------------------------------
  #
  # User-staged external model directories and files.  Definitions:
  #
  # USE_USER_STAGED_EXTRN_FILES:
  # Flag that determines whether or not the workflow will look for the 
  # external model files needed for generating ICs in user-specified
  # directories.
  #
  # EXTRN_MDL_SOURCE_BASEDIR_ICS:
  # Directory in which to look for external model files for generating ICs.
  # If USE_USER_STAGED_EXTRN_FILES is set to true, the workflow looks in 
  # this directory (specifically, in a subdirectory under this directory 
  # named "YYYYMMDDHH" consisting of the starting date and cycle hour of 
  # the forecast, where YYYY is the 4-digit year, MM the 2-digit month, DD 
  # the 2-digit day of the month, and HH the 2-digit hour of the day) for 
  # the external model files specified by the array EXTRN_MDL_FILES_ICS 
  # (these files will be used to generate the ICs on the native FV3-LAM 
  # grid).  This variable is not used if USE_USER_STAGED_EXTRN_FILES is 
  # set to false.
  # 
  # EXTRN_MDL_FILES_ICS:
  # Array containing templates of the names of the files to search for in
  # the directory specified by EXTRN_MDL_SOURCE_BASEDIR_ICS.  This
  # variable is not used if USE_USER_STAGED_EXTRN_FILES is set to false.
  # A single template should be used for each model file type that is
  # meant to be used. You may use any of the Python-style templates
  # allowed in the ush/retrieve_data.py script. To see the full list of
  # supported templates, run that script with a -h option. Here is an example of
  # setting FV3GFS nemsio input files:
  #   EXTRN_MDL_FILES_ICS=( gfs.t{hh}z.atmf{fcst_hr:03d}.nemsio \
  #   gfs.t{hh}z.sfcf{fcst_hr:03d}.nemsio )
  # Or for FV3GFS grib files:
  #   EXTRN_MDL_FILES_ICS=( gfs.t{hh}z.pgrb2.0p25.f{fcst_hr:03d} )
  #
  #-----------------------------------------------------------------------
  #
  USE_USER_STAGED_EXTRN_FILES: false
  EXTRN_MDL_SOURCE_BASEDIR_ICS: ""
  EXTRN_MDL_FILES_ICS: ""

#----------------------------
# EXTRN LBCS config parameters
#-----------------------------
task_get_extrn_lbcs:
  TN_GET_EXTRN_LBCS: "get_extrn_lbcs"
  TN_GET_EXTRN_LBCS_LONG: "get_extrn_lbcs_long"
  NNODES_GET_EXTRN_LBCS: 1
  PPN_GET_EXTRN_LBCS: 1
  MEM_GET_EXTRN_LBCS: 2G
  WTIME_GET_EXTRN_LBCS: 00:45:00
  MAXTRIES_GET_EXTRN_LBCS: 1
  #
  #-----------------------------------------------------------------------
  #
  # EXTRN_MDL_NAME_LBCS:
  #`The name of the external model that will provide fields from which 
  # lateral boundary condition (LBC) files (except for the 0-th hour LBC 
  # file) will be generated for input into the forecast model.
  #
  # LBC_SPEC_INTVL_HRS:
  # The interval (in integer hours) with which LBC files will be generated.
  # We will refer to this as the boundary update interval.  Note that the
  # model specified in EXTRN_MDL_NAME_LBCS must have data available at a
  # frequency greater than or equal to that implied by LBC_SPEC_INTVL_HRS.
  # For example, if LBC_SPEC_INTVL_HRS is set to 6, then the model must have
  # data availble at least every 6 hours.  It is up to the user to ensure 
  # that this is the case.
  #
  # EXTRN_MDL_LBCS_OFFSET_HRS:
  # Users may wish to use lateral boundary conditions from a forecast that
  # was started earlier than the initial time for the FV3 forecast
  # configured here. This variable sets the number of hours earlier
  # the external model started than when the FV3 forecast configured here
  # should start. For example, the forecast should use lateral boundary
  # conditions from the GFS started 6 hours earlier, then
  # EXTRN_MDL_LBCS_OFFSET_HRS=6. Defaults to 0 except for RAP, which
  # uses a 3 hour offset.
  #
  # FV3GFS_FILE_FMT_LBCS:
  # If using the FV3GFS model as the source of the LBCs (i.e. if 
  # EXTRN_MDL_NAME_LBCS is set to "FV3GFS"), this variable specifies the 
  # format of the model files to use when generating the LBCs.
  #
  #-----------------------------------------------------------------------
  #
  EXTRN_MDL_NAME_LBCS: "FV3GFS"
  LBC_SPEC_INTVL_HRS: 6
  EXTRN_MDL_LBCS_OFFSET_HRS: '{{ 3 if EXTRN_MDL_NAME_LBCS == "RAP" else 0 }}'
  FV3GFS_FILE_FMT_LBCS: "nemsio"
  #
  #-----------------------------------------------------------------------
  #
  # LBCS_SEARCH_HRS:
  #  When search boundary conditions tasks from previous cycles in prep_cyc step,
  #  For example: 0 means search start for the same cycle lbcs task.
  #               1 means search start for 1-h previous cycle lbcs task.
  #               2 means search start for 2-h previous cycle lbcs task.
  #
  # EXTRN_MDL_LBCS_SEARCH_OFFSET_HRS:
  #  When search boundary conditions from previous cycles in prep_start step,
  #  the search will start at cycle before (this parameter) of current cycle.
  #  For example: 0 means search start at the same cycle lbcs directory.
  #               1 means search start at 1-h previous cycle  lbcs directory.
  #               2 means search start at 2-h previous cycle  lbcs directory.
  #
  #-----------------------------------------------------------------------
  #
  LBCS_SEARCH_HRS: 6
  EXTRN_MDL_LBCS_SEARCH_OFFSET_HRS: 0
  #
  #-----------------------------------------------------------------------
  #
  # EXTRN_MDL_SYSBASEDIR_LBCS:
  # Same as EXTRN_MDL_SYSBASEDIR_ICS but for LBCs.
  #
  # Note that this must be defined as a null string here so that if it is 
  # specified by the user in the experiment configuration file, it remains 
  # set to those values, and if not, it gets set to machine-dependent 
  # values.
  #
  #-----------------------------------------------------------------------
  #
  EXTRN_MDL_SYSBASEDIR_LBCS: ''
  #
  #-----------------------------------------------------------------------
  #
  # User-staged external model directories and files.  Definitions:
  #
  # USE_USER_STAGED_EXTRN_FILES:
  # Analogous to USE_USER_STAGED_EXTRN_FILES in ICS but for LBCs
  #
  # EXTRN_MDL_SOURCE_BASEDIR_LBCS:
  # Analogous to EXTRN_MDL_SOURCE_BASEDIR_ICS but for LBCs instead of ICs.
  #
  # EXTRN_MDL_FILES_LBCS:
  # Analogous to EXTRN_MDL_FILES_ICS but for LBCs instead of ICs.
  #
  #-----------------------------------------------------------------------
  #
  USE_USER_STAGED_EXTRN_FILES: false
  EXTRN_MDL_SOURCE_BASEDIR_LBCS: ""
  EXTRN_MDL_FILES_LBCS: ""

#----------------------------
# PREPSTART config parameters
#-----------------------------
task_run_prepstart:
  TN_PREP_START: "prep_start"
  TN_PREP_CYC: "prep_cyc"
  TN_PREP_CYC_SPINUP: "prep_cyc_spinup"
  TN_PREP_CYC_PROD: "prep_cyc_prod"
  TN_PREP_CYC_ENSMEAN: "prep_cyc_ensmean"
  TN_CALC_ENSMEAN: "calc_ensmean"
  NNODES_RUN_PREPSTART: 1
  PPN_RUN_PREPSTART: 1
  MEM_RUN_PREPSTART: 24G
  WTIME_RUN_PREPSTART: 00:10:00
  WTIME_RUN_PREPSTART_ENSMEAN: 00:10:00
  MAXTRIES_RUN_PREPSTART: 1

#----------------------------
# PROCESS RADARREF config parameters
#-----------------------------
task_process_radarref:
  TN_PROCESS_RADAR_REF: "process_radarref"
  NNODES_PROCESS_RADARREF: 2
  PPN_PROCESS_RADARREF: 24
  WTIME_PROCESS_RADARREF: 00:30:00
  MAXTRIES_PROCESS_RADARREF: 1

  RADAR_REF_THINNING: 1
  #
  #-----------------------------------------------------------------------
  #
  # Parameters for observation preprocess.
  # RADARREFL_MINS:
  #   minute from the hour that the NSSL mosaic files will be searched for 
  #      data preprocess
  # RADARREFL_TIMELEVEL:
  #   time level (minute) from the hour that the NSSL mosaic files will be generated 
  #
  #-----------------------------------------------------------------------
  #
  RADARREFL_MINS: [0, 1, 2, 3]
  RADARREFL_TIMELEVEL: [0]

#----------------------------
# REF2TTEN config parameters
#-----------------------------
task_run_ref2tten:
  TN_RADAR_REFL2TTEN: "radar_refl2tten"
  NNODES_RUN_REF2TTEN: 1
  PPN_RUN_REF2TTEN: 1
  MEM_RUN_REF2TTEN: 20G
  WTIME_RUN_REF2TTEN: 00:30:00
  MAXTRIES_RUN_REF2TTEN: 1

#----------------------------
# PROCESS LIGHTNING config parameters
#-----------------------------
task_process_lightning:
  TN_PROCESS_LIGHTNING: "process_lightning"
  NNODES_PROCESS_LIGHTNING: 1
  PPN_PROCESS_LIGHTNING: 1
  MEM_PROCESS_LIGHTNING: 2G
  WTIME_PROCESS_LIGHTNING: 00:30:00
  MAXTRIES_PROCESS_LIGHTNING: 1

#----------------------------
# PROCESS BUFR config parameters
#-----------------------------
task_process_bufr:
  TN_PROCESS_BUFR: "process_bufr"
  NNODES_PROCESS_BUFR: 1
  PPN_PROCESS_BUFR: 1
  MEM_PROCESS_BUFR: 20G
  WTIME_PROCESS_BUFR: 00:30:00
  MAXTRIES_PROCESS_BUFR: 1

#----------------------------
# PROCESS SMOKE config parameters
#-----------------------------
task_process_smoke:
  TN_PROCESS_SMOKE: "process_smoke"
  NNODES_PROCESS_SMOKE: 1
  PPN_PROCESS_SMOKE: 1
  MEM_PROCESS_SMOKE: 80G
  WTIME_PROCESS_SMOKE: 00:30:00
  MAXTRIES_PROCESS_SMOKE: 1

#----------------------------
# ANAL config parameters
#-----------------------------
task_run_anal:
  TN_ANAL_GSI: "anal_gsi_input"
  TN_OBSERVER_GSI: "observer_gsi"
  TN_OBSERVER_GSI_ENSMEAN: "observer_gsi_ensmean"
  NNODES_RUN_ANAL: 16
  PPN_RUN_ANAL: 24
  NCORES_RUN_ANAL: 4
  NCORES_RUN_OBSERVER: 4
  WTIME_RUN_ANAL: 00:30:00
  MAXTRIES_RUN_ANAL: 1
  KMP_AFFINITY_RUN_ANAL: "scatter"
  OMP_NUM_THREADS_RUN_ANAL: 1
  OMP_STACKSIZE_RUN_ANAL: "1024m"

#----------------------------
# POSTANAL config parameters
#-----------------------------
task_run_postanal:
  TN_POSTANAL: "postanal_input"
  NNODES_RUN_POSTANAL: 1
  PPN_RUN_POSTANAL: 1
  WTIME_RUN_POSTANAL: 00:30:00
  MAXTRIES_RUN_POSTANAL: 1
  KMP_AFFINITY_RUN_POSTANAL: "scatter"
  OMP_NUM_THREADS_RUN_POSTANAL: 1
  OMP_STACKSIZE_RUN_POSTANAL: "1024m"

#----------------------------
# CLDANAL_NONVAR config parameters
#-----------------------------
task_run_nonvarcldanl:
  TN_CLDANL_NONVAR: "cldanl_nonvar"
  NNODES_RUN_NONVARCLDANL: 1
  PPN_RUN_NONVARCLDANL: 1
  MEM_RUN_NONVARCLDANL: 20G
  WTIME_RUN_NONVARCLDANL: 00:30:00
  MAXTRIES_RUN_NONVARCLDANL: 1

#----------------------------
# JEDI ENVAR IODA config parameters
#-----------------------------
task_run_jedi_envar_ioda:
  TN_JEDI_ENVAR_IODA: "jedi_envar_ioda"
  NNODES_RUN_JEDI_ENVAR_IODA: 1
  PPN_RUN_JEDI_ENVAR_IODA: 1
  MEM_RUN_JEDI_ENVAR_IODA: 20G
  WTIME_RUN_JEDI_ENVAR_IODA: 00:30:00
  MAXTRIES_RUN_JEDI_ENVAR_IODA: 1

#----------------------------
# RUN ENKF config parameters
#-----------------------------
task_run_enkf:
  TN_RUN_ENKF: "run_enkf"
  NNODES_RUN_ENKF: 90
  PPN_RUN_ENKF: 1
  NCORES_RUN_ENKF: 4
  WTIME_RUN_ENKF: 01:00:00
  MAXTRIES_RUN_ENKF: 1
  KMP_AFFINITY_RUN_ENKF: "scatter"
  OMP_NUM_THREADS_RUN_ENKF: 1
  OMP_STACKSIZE_RUN_ENKF: "1024m"

#----------------------------
# RECENTER config parameters
#-----------------------------
task_run_recenter:
  TN_RUN_RECENTER: "run_recenter"
  NNODES_RUN_RECENTER: 2
  PPN_RUN_RECENTER: 20
  WTIME_RUN_RECENTER: 01:00:00
  MAXTRIES_RUN_RECENTER: 1

#----------------------------
# SAVE RESTART config parameters
#-----------------------------
task_save_restart:
  TN_SAVE_RESTART: "save_restart"
  NNODES_SAVE_RESTART: 1
  PPN_SAVE_RESTART: 1
  MEM_SAVE_RESTART: 2G
  WTIME_SAVE_RESTART: 00:15:00
  MAXTRIES_SAVE_RESTART: 1

#----------------------------
# SAVE INPUT config parameters
#-----------------------------
task_save_input:
  TN_SAVE_INPUT: "save_input"
  NNODES_SAVE_INPUT: 1
  PPN_SAVE_INPUT: 1
  MEM_SAVE_INPUT: 2G
  WTIME_SAVE_INPUT: 00:15:00
  MAXTRIES_SAVE_INPUT: 1

#----------------------------
# RUN PRDGEN config parameters
#-----------------------------
task_run_prdgen:
  TN_RUN_PRDGEN: "run_prdgen"
  NNODES_RUN_PRDGEN: 1
  PPN_RUN_PRDGEN: 1
  MEM_RUN_PRDGEN: 24G
  WTIME_RUN_PRDGEN: 00:40:00
  MAXTRIES_RUN_PRDGEN: 1
  KMP_AFFINITY_RUN_PRDGEN: "scatter"
  OMP_NUM_THREADS_RUN_PRDGEN: 1
  OMP_STACKSIZE_RUN_PRDGEN: "1024m"
  #
  #
  #-----------------------------------------------------------------------
  #
  # Set additional output grids for wgrib2 remapping, if any 
  # Space-separated list of strings, e.g., ( "130" "242" "clue" )
  # Default is no additional grids
  #
  # Current options as of 23 Apr 2021:
  #  "130"   (CONUS 13.5 km)
  #  "200"   (Puerto Rico 16 km)
  #  "221"   (North America 32 km)
  #  "242"   (Alaska 11.25 km)
  #  "243"   (Pacific 0.4-deg)
  #  "clue"  (NSSL/SPC 3-km CLUE grid for 2020/2021)
  #  "hrrr"  (HRRR 3-km CONUS grid)
  #  "hrrre" (HRRRE 3-km CONUS grid)
  #  "rrfsak" (RRFS 3-km Alaska grid)
  #  "hrrrak" (HRRR 3-km Alaska grid)
  #
  #-----------------------------------------------------------------------
  #
  ADDNL_OUTPUT_GRIDS: []

#----------------------------
# RUN BUFRSND config parameters
#-----------------------------
task_run_bufrsnd:
  TN_RUN_BUFRSND: "run_bufrsnd"
  NNODES_RUN_BUFRSND: 1
  PPN_RUN_BUFRSND: 28
  WTIME_RUN_BUFRSND: 00:45:00
  MAXTRIES_RUN_BUFRSND: 1

#----------------------------
# MAKE ICS config parameters
#-----------------------------
task_make_ics:
  TN_MAKE_ICS: "make_ics"
  NNODES_MAKE_ICS: 4
  PPN_MAKE_ICS: 12
  WTIME_MAKE_ICS: 00:30:00
  MAXTRIES_MAKE_ICS: 1
  KMP_AFFINITY_MAKE_ICS: "scatter"
  OMP_NUM_THREADS_MAKE_ICS: 1
  OMP_STACKSIZE_MAKE_ICS: "1024m"
  #
  #-----------------------------------------------------------------------
  #
  # USE_FVCOM:
  # Flag set to update surface conditions in FV3-LAM with fields generated
  # from the Finite Volume Community Ocean Model (FVCOM). This will
  # replace lake/sea surface temperature, ice surface temperature, and ice
  # placement. FVCOM data must already be interpolated to the desired
  # FV3-LAM grid. This flag will be used in make_ics to modify sfc_data.nc
  # after chgres_cube is run by running the routine process_FVCOM.exe
  #
  # FVCOM_WCSTART:
  # Define if this is a "warm" start or a "cold" start. Setting this to 
  # "warm" will read in sfc_data.nc generated in a RESTART directory.
  # Setting this to "cold" will read in the sfc_data.nc generated from 
  # chgres_cube in the make_ics portion of the workflow.
  #
  # PREP_FVCOM:
  # Flag set to interpolate FVCOM data to the desired FV3-LAM grid.
  #
  # FVCOM_DIR:
  # User defined directory where FVCOM data already interpolated to FV3-LAM
  # grid is located. File name in this path should be "fvcom.nc" to allow
  #
  # FVCOM_FILE:
  # Name of file located in FVCOM_DIR that has FVCOM data interpolated to 
  # FV3-LAM grid. This file will be copied later to a new location and name
  # changed to fvcom.nc
  #
  #------------------------------------------------------------------------
  #
  USE_FVCOM: false
  PREP_FVCOM: false
  FVCOM_WCSTART: "cold"
  FVCOM_DIR: ""
  FVCOM_FILE: "fvcom.nc"

#----------------------------
# MAKE LBCS config parameters
#-----------------------------
task_make_lbcs:
  TN_MAKE_LBCS: "make_lbcs"
  NNODES_MAKE_LBCS: 4
  PPN_MAKE_LBCS: 12
  WTIME_MAKE_LBCS: 00:30:00
  MAXTRIES_MAKE_LBCS: 1
  KMP_AFFINITY_MAKE_LBCS: "scatter"
  OMP_NUM_THREADS_MAKE_LBCS: 1
  OMP_STACKSIZE_MAKE_LBCS: "1024m"
  LBC_SPEC_FCST_HRS: '( {% for h in range(0 if workflow_switches.DO_RRFS_DEV else task_get_extrn_lbcs.LBC_SPEC_INTVL_HRS, task_get_extrn_lbcs.LBC_SPEC_INTVL_HRS + [workflow.FCST_LEN_HRS, workflow.BOUNDARY_LEN_HRS]|max, task_get_extrn_lbcs.LBC_SPEC_INTVL_HRS) %}{{ "%d " % h }}{% endfor %} )'

#----------------------------
# FORECAST config parameters
#-----------------------------
task_run_fcst:
  TN_RUN_FCST: "run_fcst"
  NNODES_RUN_FCST: '{{ (PE_MEMBER01 + PPN_RUN_FCST - 1) // PPN_RUN_FCST }}'
  PPN_RUN_FCST: '{{ platform.NCORES_PER_NODE // OMP_NUM_THREADS_RUN_FCST }}'
  WTIME_RUN_FCST: 04:30:00
  WTIME_RUN_FCST_LONG: 04:30:00
  WTIME_RUN_FCST_SPINUP: 00:30:00
  MAXTRIES_RUN_FCST: 1
  FV3_EXEC_FP: '{{ [user.EXECdir, workflow.FV3_EXEC_FN]|path_join }}'
  #
  #-----------------------------------------------------------------------
  #
  # KMP_AFFINITY_*:
  # From Intel: "The Intel® runtime library has the ability to bind OpenMP
  # threads to physical processing units. The interface is controlled using
  # the KMP_AFFINITY environment variable. Depending on the system (machine)
  # topology, application, and operating system, thread affinity can have a
  # dramatic effect on the application speed. 
  #
  # Thread affinity restricts execution of certain threads (virtual execution
  # units) to a subset of the physical processing units in a multiprocessor 
  # computer. Depending upon the topology of the machine, thread affinity can
  # have a dramatic effect on the execution speed of a program."
  #
  # For more information, see the following link:
  # https://software.intel.com/content/www/us/en/develop/documentation/cpp-
  # compiler-developer-guide-and-reference/top/optimization-and-programming-
  # guide/openmp-support/openmp-library-support/thread-affinity-interface-
  # linux-and-windows.html
  # 
  # OMP_NUM_THREADS_*:
  # The number of OpenMP threads to use for parallel regions.
  # 
  # OMP_STACKSIZE_*:
  # Controls the size of the stack for threads created by the OpenMP 
  # implementation.
  #
  # Note that settings for the make_grid and make_orog tasks are not 
  # included below as they do not use parallelized code.
  #
  #-----------------------------------------------------------------------
  #
  KMP_AFFINITY_RUN_FCST: "scatter"
  OMP_NUM_THREADS_RUN_FCST: 2    # atmos_nthreads in model_configure
  OMP_STACKSIZE_RUN_FCST: "1024m"
  #
  #-----------------------------------------------------------------------
  #
  # Set model_configure parameters.  Definitions:
  #
  # DT_ATMOS:
  # The main forecast model integration time step.  As described in the 
  # forecast model documentation, "It corresponds to the frequency with 
  # which the top level routine in the dynamics is called as well as the 
  # frequency with which the physics is called."
  #
  # WRITE_DOPOST:
  # Flag that determines whether or not to use the inline post feature 
  # [i.e. calling the Unified Post Processor (UPP) from within the weather 
  # model].  If this is set to true, the TN_RUN_POST task is deactivated 
  # (i.e. RUN_TASK_RUN_POST is set to false) to avoid unnecessary 
  # computations.
  #
  #-----------------------------------------------------------------------
  #
  DT_ATMOS: ""
  WRITE_DOPOST: false

  #
  #-----------------------------------------------------------------------
  #
  # Set computational parameters for the forecast.  Definitions:
  #
  # LAYOUT_X, LAYOUT_Y:
  # The number of MPI tasks (processes) to use in the two horizontal 
  # directions (x and y) of the regional grid when running the forecast 
  # model.
  #
  # BLOCKSIZE:
  # The amount of data that is passed into the cache at a time.
  #
  # IO_LAYOUT_X,IO_LAYOUT_Y:
  # When wrtie out restrat files, how many subdomain files will be write in
  # x and y directory. Right now, please always set IO_LAYOUT_X=1.
  # LAYOUT_Y/IO_LAYOUT_Y needs to be a integer number.
  #
  # Here, we set these parameters to null strings.  This is so that, for 
  # any one of these parameters:
  #
  # 1) If the experiment is using a predefined grid, then if the user 
  #    sets the parameter in the user-specified experiment configuration 
  #    file (EXPT_CONFIG_FN), that value will be used in the forecast(s).
  #    Otherwise, the default value of the parameter for that predefined 
  #    grid will be used.
  #
  # 2) If the experiment is not using a predefined grid (i.e. it is using
  #    a custom grid whose parameters are specified in the experiment 
  #    configuration file), then the user must specify a value for the 
  #    parameter in that configuration file.  Otherwise, the parameter 
  #    will remain set to a null string, and the experiment generation 
  #    will fail because the generation scripts check to ensure that all 
  #    the parameters defined in this section are set to non-empty strings
  #    before creating the experiment directory.
  #
  #-----------------------------------------------------------------------
  #
  LAYOUT_X: '{{ LAYOUT_X }}'
  LAYOUT_Y: '{{ LAYOUT_Y }}'
  BLOCKSIZE: '{{ BLOCKSIZE }}'
  IO_LAYOUT_X: 1
  IO_LAYOUT_Y: 1
  #
  #-----------------------------------------------------------------------
  #
  # Set write-component (quilting) parameters.  Definitions:
  #
  # QUILTING:
  # Flag that determines whether or not to use the write component for 
  # writing output files to disk. The regional grid requires the use of 
  # the write component, so users should not change the default value. 
  #
  # PRINT_ESMF:
  # Flag for whether or not to output extra (debugging) information from
  # ESMF routines. Must be true or false. Note that the write
  # component uses ESMF library routines to interpolate from the native
  # forecast model grid to the user-specified output grid (which is defined 
  # in the model configuration file "model_configure" in the forecast's  
  # run directory).
  # 
  # WRTCMP_write_groups:
  # The number of write groups (i.e. groups of MPI tasks) to use in the
  # write component.
  #
  # WRTCMP_write_tasks_per_group:
  # The number of MPI tasks to allocate for each write group.
  #
  # WRTCMP_output_grid:
  # Sets the type (coordinate system) of the write component grid. The 
  # default empty string forces the user to set a valid value for 
  # WRTCMP_output_grid in config.yaml if specifying a *custom* grid. When 
  # creating an experiment with a user-defined grid, this parameter must 
  # be specified or the experiment will fail. 
  #
  # WRTCMP_cen_lon:
  # Longitude (in degrees) of the center of the write component grid. Can 
  # usually be set to the corresponding value from the native grid.
  #
  # WRTCMP_cen_lat:
  # Latitude (in degrees) of the center of the write component grid. Can 
  # usually be set to the corresponding value from the native grid.
  # WRTCMP_lon_lwr_left:
  # Longitude (in degrees) of the center of the lower-left (southwest) 
  # cell on the write component grid. If using the "rotated_latlon" 
  # coordinate system, this is expressed in terms of the rotated longitude. 
  # Must be set manually when running an experiment with a user-defined grid.
  #
  # WRTCMP_lat_lwr_left:
  # Latitude (in degrees) of the center of the lower-left (southwest) cell 
  # on the write component grid. If using the "rotated_latlon" coordinate 
  # system, this is expressed in terms of the rotated latitude. Must be set 
  # manually when running an experiment with a user-defined grid.
  # 
  # -----------------------------------------------------------------------
  # 
  # WRTCMP_lon_upr_rght:
  # Longitude (in degrees) of the center of the upper-right (northeast) cell 
  # on the write component grid (expressed in terms of the rotated longitude).
  #
  # WRTCMP_lat_upr_rght:
  # Latitude (in degrees) of the center of the upper-right (northeast) cell 
  # on the write component grid (expressed in terms of the rotated latitude).
  #
  # WRTCMP_dlon:
  # Size (in degrees) of a grid cell on the write component grid (expressed 
  # in terms of the rotated longitude).
  #
  # WRTCMP_dlat:
  # Size (in degrees) of a grid cell on the write component grid (expressed 
  # in terms of the rotated latitude).
  #
  # -----------------------------------------------------------------------
  # 
  # WRTCMP_stdlat1:
  # First standard latitude (in degrees) in definition of Lambert conformal 
  # projection.
  #
  # WRTCMP_stdlat2:
  # Second standard latitude (in degrees) in definition of Lambert conformal 
  # projection.
  #
  # WRTCMP_nx:
  # Number of grid points in the x-coordinate of the Lambert conformal 
  # projection.
  #
  # WRTCMP_ny:
  # Number of grid points in the y-coordinate of the Lambert conformal 
  # projection.
  #
  # WRTCMP_dx:
  # Grid cell size (in meters) along the x-axis of the Lambert conformal 
  # projection.
  #
  # WRTCMP_dy:
  # Grid cell size (in meters) along the y-axis of the Lambert conformal 
  # projection. 
  #
  #-----------------------------------------------------------------------
  #
  QUILTING: true
  PRINT_ESMF: false

  PE_MEMBER01: '{{ LAYOUT_Y * LAYOUT_X + WRTCMP_write_groups * WRTCMP_write_tasks_per_group if QUILTING else LAYOUT_Y * LAYOUT_X}}'
  
  WRTCMP_write_groups: ""
  WRTCMP_write_tasks_per_group: ""
  
  WRTCMP_output_grid: "''"
  WRTCMP_cen_lon: ""
  WRTCMP_cen_lat: ""
  WRTCMP_lon_lwr_left: ""
  WRTCMP_lat_lwr_left: ""
  #
  # The following are used only for the case of WRTCMP_output_grid set to
  # "'rotated_latlon'".
  #
  WRTCMP_lon_upr_rght: ""
  WRTCMP_lat_upr_rght: ""
  WRTCMP_dlon: ""
  WRTCMP_dlat: ""
  #
  # The following are used only for the case of WRTCMP_output_grid set to
  # "'lambert_conformal'".
  #
  WRTCMP_stdlat1: ""
  WRTCMP_stdlat2: ""
  WRTCMP_nx: ""
  WRTCMP_ny: ""
  WRTCMP_dx: ""
  WRTCMP_dy: ""
  #
  #-----------------------------------------------------------------------
  #
  # Flag that determines whether MERRA2 aerosol climatology data and
  # lookup tables for optics properties are obtained
  #
  #-----------------------------------------------------------------------
  #
  USE_MERRA_CLIMO: '{{ workflow.CCPP_PHYS_SUITE == "FV3_GFS_v15_thompson_mynn_lam3km" or workflow.CCPP_PHYS_SUITE == "FV3_GFS_v17_p8" }}'
  #
  #-----------------------------------------------------------------------
  #
  # FH_DFI_RADAR:
  # the forecast hour to use radar tten, this is used  to set the fh_dfi_radar 
  # parameter in input.nml, e.g. FH_DFI_RADAR="0.0,0.25,0.5,0.75,1.0"
  # will set fh_dfi_radar = 0.0,0.25,0.5,0.75,1.0 in input.nml* and
  # it tells the model to read at the 0, 15, 30, 45 minutes,
  # and apply radar tten from 0-60 minutes of forecasts.
  #
  # Here, we set these parameters to null strings.  This is so that, for 
  # any one of these parameters:
  #
  # 1) If the experiment is using a predefined grid, then if the user 
  #    sets the parameter in the user-specified experiment configuration 
  #    file (EXPT_CONFIG_FN), that value will be used in the forecast(s).
  #    Otherwise, the default value of the parameter for that predefined 
  #    grid will be used.
  #
  # 2) If the experiment is not using a predefined grid (i.e. it is using
  #    a custom grid whose parameters are specified in the experiment 
  #    configuration file), then the user must specify a value for the 
  #    parameter in that configuration file.  Otherwise, the parameter 
  #    will remain set to a null string, and the experiment generation 
  #    will fail because the generation scripts check to ensure that all 
  #    the parameters defined in this section are set to non-empty strings
  #    before creating the experiment directory.
  #
  #
  # NFHOUT: 
  # Output frequency in hours after forecast hour "nfhmax_hf".
  #
  # NFHMAX_HF:
  # Number of forecast hours until output frequency "nfhout" takes affect. 
  #
  # NFHOUT_HF:
  # Output frequency in hours until forecast hour "nfhmax_hf".
  #
  # NSOUT
  #   setup frequency of writing out forecast files in time steps
  # NSOUT_MIN
  #   setup frequency of writing out forecast files in minutes
  #
  #-----------------------------------------------------------------------
  #
  FH_DFI_RADAR: -20000000000
  NFHOUT: 1
  NFHMAX_HF: 60
  NFHOUT_HF: 1
  NSOUT: 0
  NSOUT_MIN: 0

#----------------------------
# POST config parameters
#-----------------------------
task_run_post:
  TN_RUN_POST: "run_post"
  NNODES_RUN_POST: 2
  PPN_RUN_POST: 24
  WTIME_RUN_POST: 00:15:00
  MAXTRIES_RUN_POST: 2
  KMP_AFFINITY_RUN_POST: "scatter"
  OMP_NUM_THREADS_RUN_POST: 1
  OMP_STACKSIZE_RUN_POST: "1024m"
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters associated with subhourly forecast model output and 
  # post-processing.
  #
  # SUB_HOURLY_POST:
  # Flag that indicates whether the forecast model will generate output 
  # files on a sub-hourly time interval (e.g. 10 minutes, 15 minutes, etc).
  # This will also cause the post-processor to process these sub-hourly
  # files.  If ths is set to true, then DT_SUBHOURLY_POST_MNTS should be 
  # set to a value between "00" and "59".
  #
  # DT_SUB_HOURLY_POST_MNTS:
  # Time interval in minutes between the forecast model output files.  If 
  # SUB_HOURLY_POST is set to true, this needs to be set to a two-digit 
  # integer between "01" and "59".  This is not used if SUB_HOURLY_POST is
  # not set to true.  Note that if SUB_HOURLY_POST is set to true but
  # DT_SUB_HOURLY_POST_MNTS is set to "00", SUB_HOURLY_POST will get reset
  # to false in the experiment generation scripts (there will be an 
  # informational message in the log file to emphasize this).
  #
  #-----------------------------------------------------------------------
  #
  SUB_HOURLY_POST: false
  DT_SUBHOURLY_POST_MNTS: 0
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters for customizing the post-processor (UPP).  Definitions:
  #
  # USE_CUSTOM_POST_CONFIG_FILE:
  # Flag that determines whether a user-provided custom configuration file
  # should be used for post-processing the model data. If this is set to
  # true, then the workflow will use the custom post-processing (UPP) 
  # configuration file specified in CUSTOM_POST_CONFIG_FP. Otherwise, a 
  # default configuration file provided in the UPP repository will be 
  # used.
  #
  # CUSTOM_POST_CONFIG_FP:
  # The full path to the custom post flat file, including filename, to be 
  # used for post-processing. This is only used if CUSTOM_POST_CONFIG_FILE
  # is set to true.
  #
  # CUSTOM_POST_PARAMS_FP:
  # The full path to the custom post params file, including filename, to be 
  # used for post-processing. This is only used if CUSTOM_POST_CONFIG_FILE
  # is set to "TRUE".
  #
  # POST_FULL_MODEL_NAME
  # The full module name required by UPP and set in the itag file
  #
  # POST_SUB_MODEL_NAME
  # The SUB module name required by UPP and set in the itag file
  #
  # TESTBED_FIELDS_FN
  # The file which lists grib2 fields to be extracted to bgsfc for testbed
  # Empty string means no need to generate bgsfc for testbed
  #
  # POST_OUTPUT_DOMAIN_NAME:
  # Domain name (in lowercase) used in constructing the names of the output 
  # files generated by UPP [which is called either by running the TN_RUN_POST 
  # task or by activating the inline post feature (WRITE_DOPOST set to true)].  
  # The post output files are named as follows:
  # 
  #   $NET.tHHz.[var_name].f###.${POST_OUTPUT_DOMAIN_NAME}.grib2
  # 
  # If using a custom grid, POST_OUTPUT_DOMAIN_NAME must be specified by 
  # the user.  If using a predefined grid, POST_OUTPUT_DOMAIN_NAME defaults
  # to PREDEF_GRID_NAME.  Note that this variable is first changed to lower
  # case before being used to construct the file names.
  #
  #-----------------------------------------------------------------------
  #
  POST_OUTPUT_DOMAIN_NAME: '{{ workflow.PREDEF_GRID_NAME }}'
  USE_CUSTOM_POST_CONFIG_FILE: false
  CUSTOM_POST_CONFIG_FP: ""
  CUSTOM_POST_PARAMS_FP: ""
  POST_FULL_MODEL_NAME: "FV3R"
  POST_SUB_MODEL_NAME: "NONE"
  TESTBED_FIELDS_FN: ""
  TESTBED_FIELDS_FN2: ""

#----------------------------
# PLOT_ALLVARS config parameters
#-----------------------------
task_plot_allvars:
  TN_PLOT_ALLVARS: "plot_allvars"
  NNODES_PLOT_ALLVARS: 1
  PPN_PLOT_ALLVARS: 24
  WTIME_PLOT_ALLVARS: 01:00:00
  MAXTRIES_PLOT_ALLVARS: 1
  #-------------------------------------------------------------------------
  # Reference experiment's COMOUT directory. This is where the GRIB2 files 
  # from postprocessing are located. Make this a template to compare
  # multiple cycle and dates. COMOUT_REF should end with:
  #    nco mode: $PDY/$cyc
  #    community mode: $PDY$cyc/postprd
  # We don't do this inside the code, so that we can compare nco vs com runs.
  #-------------------------------------------------------------------------
  COMOUT_REF: ""
  #------------------------------
  # Plot fcts start and increment
  #------------------------------
  PLOT_FCST_START: 0
  PLOT_FCST_INC: 3
  #-----------------------------------
  # By default the end is FCST_LEN_HRS
  #-----------------------------------
  PLOT_FCST_END: ""
  #------------------------------------------------------------------------------
  # Domains to plot. Currently supported are either "conus" or "regional" or both
  #-------------------------------------------------------------------------------
  PLOT_DOMAINS: ["conus"]

#----------------------------
# GET OBS CCPA config parameters
#-----------------------------
task_get_obs_ccpa:
  TN_GET_OBS_CCPA: "get_obs_ccpa"
  NNODES_GET_OBS_CCPA: 1
  PPN_GET_OBS_CCPA: 1
  MEM_GET_OBS_CCPA: 2G
  WTIME_GET_OBS_CCPA: 00:45:00
  MAXTRIES_GET_OBS_CCPA: 1

#----------------------------
# GET OBS MRMS config parameters
#-----------------------------
task_get_obs_mrms:
  TN_GET_OBS_MRMS: "get_obs_mrms"
  NNODES_GET_OBS_MRMS: 1
  PPN_GET_OBS_MRMS: 1
  MEM_GET_OBS_MRMS: 2G
  WTIME_GET_OBS_MRMS: 00:45:00
  MAXTRIES_GET_OBS_MRMS: 1

#----------------------------
# GET OBS NDAS config parameters
#-----------------------------
task_get_obs_ndas:
  TN_GET_OBS_NDAS: "get_obs_ndas"
  NNODES_GET_OBS_NDAS: 1
  PPN_GET_OBS_NDAS: 1
  MEM_GET_OBS_NDAS: 2G
  WTIME_GET_OBS_NDAS: 02:00:00
  MAXTRIES_GET_OBS_NDAS: 1

#----------------------------
# run_met_gridstat_vx_apcp01h config parameters
#-----------------------------
task_run_met_gridstat_vx_apcp01h:
  TN_RUN_MET_GRIDSTAT_VX_APCP01h: "run_MET_GridStat_vx_APCP01h"
  NNODES_RUN_MET_GRIDSTAT_VX_APCP01H: 1
  PPN_RUN_MET_GRIDSTAT_VX_APCP01H: 1
  MEM_RUN_MET_GRIDSTAT_VX_APCP01H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_APCP01H: 02:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_APCP01H: 2

#----------------------------
# run_met_gridstat_vx_apcp03h config parameters
#-----------------------------
task_run_met_gridstat_vx_apcp03h:
  TN_RUN_MET_GRIDSTAT_VX_APCP03H: "run_MET_GridStat_vx_APCP03h"
  NNODES_RUN_MET_GRIDSTAT_VX_APCP03H: 1
  PPN_RUN_MET_GRIDSTAT_VX_APCP03H: 1
  MEM_RUN_MET_GRIDSTAT_VX_APCP03H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_APCP03H: 02:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_APCP03H: 2

#----------------------------
# run_met_gridstat_vx_apcp06h config parameters
#-----------------------------
task_run_met_gridstat_vx_apcp06h:
  TN_RUN_MET_GRIDSTAT_VX_APCP06H: "run_MET_GridStat_vx_APCP06h"
  NNODES_RUN_MET_GRIDSTAT_VX_APCP06H: 1
  PPN_RUN_MET_GRIDSTAT_VX_APCP06H: 1
  MEM_RUN_MET_GRIDSTAT_VX_APCP06H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_APCP06H: 02:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_APCP06H: 2

#----------------------------
# run_met_gridstat_vx_apcp24h config parameters
#-----------------------------
task_run_met_gridstat_vx_apcp24h:
  TN_RUN_MET_GRIDSTAT_VX_APCP24H: "run_MET_GridStat_vx_APCP24h"
  NNODES_RUN_MET_GRIDSTAT_VX_APCP24H: 1
  PPN_RUN_MET_GRIDSTAT_VX_APCP24H: 1
  MEM_RUN_MET_GRIDSTAT_VX_APCP24H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_APCP24H: 02:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_APCP24H: 2

#----------------------------
# run_met_gridstat_vx_refc config parameters
#-----------------------------
task_run_met_gridstat_vx_refc:
  TN_RUN_MET_GRIDSTAT_VX_REFC: "run_MET_GridStat_vx_REFC"
  NNODES_RUN_MET_GRIDSTAT_VX_REFC: 1
  PPN_RUN_MET_GRIDSTAT_VX_REFC: 1
  MEM_RUN_MET_GRIDSTAT_VX_REFC: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_REFC: 02:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_REFC: 2

#----------------------------
# run_met_gridstat_vx_retop config parameters
#-----------------------------
task_run_met_gridstat_vx_retop:
  TN_RUN_MET_GRIDSTAT_VX_RETOP: "run_MET_GridStat_vx_RETOP"
  NNODES_RUN_MET_GRIDSTAT_VX_RETOP: 1
  PPN_RUN_MET_GRIDSTAT_VX_RETOP: 1
  MEM_RUN_MET_GRIDSTAT_VX_RETOP: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_RETOP: 02:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_RETOP: 2

#----------------------------
# run_met_pointstat_vx_sfc config parameters
#-----------------------------
task_run_met_pointstat_vx_sfc:
  TN_RUN_MET_POINTSTAT_VX_SFC: "run_MET_PointStat_vx_SFC"
  NNODES_RUN_MET_POINTSTAT_VX_SFC: 1
  PPN_RUN_MET_POINTSTAT_VX_SFC: 1
  MEM_RUN_MET_POINTSTAT_VX_SFC: 2G
  WTIME_RUN_MET_POINTSTAT_VX_SFC: 01:00:00
  MAXTRIES_RUN_MET_POINTSTAT_VX_SFC: 2

#----------------------------
# run_met_pointstat_vx_upa config parameters
#-----------------------------
task_run_met_pointstat_vx_upa:
  TN_RUN_MET_POINTSTAT_VX_UPA: "run_MET_PointStat_vx_UPA"
  NNODES_RUN_MET_POINTSTAT_VX_UPA: 1
  PPN_RUN_MET_POINTSTAT_VX_UPA: 1
  MEM_RUN_MET_POINTSTAT_VX_UPA: 2G
  WTIME_RUN_MET_POINTSTAT_VX_UPA: 01:00:00
  MAXTRIES_RUN_MET_POINTSTAT_VX_UPA: 2

#----------------------------
# run_met_ensemblestat_vx_apcp01h config parameters
#-----------------------------
task_run_met_ensemblestat_vx_apcp01h:
  TN_RUN_MET_ENSEMBLESTAT_VX_APCP01H: "run_MET_EnsembleStat_vx_APCP01h"
  NNODES_RUN_MET_ENSEMBLESTAT_VX_APCP01H: 1
  PPN_RUN_MET_ENSEMBLESTAT_VX_APCP01H: 1
  MEM_RUN_MET_ENSEMBLESTAT_VX_APCP01H: 2G
  WTIME_RUN_MET_ENSEMBLESTAT_VX_APCP01H: 01:00:00
  MAXTRIES_RUN_MET_ENSEMBLESTAT_VX_APCP01H: 2

#----------------------------
# run_met_ensemblestat_vx_apcp03h config parameters
#-----------------------------
task_run_met_ensemblestat_vx_apcp03h:
  TN_RUN_MET_ENSEMBLESTAT_VX_APCP03H: "run_MET_EnsembleStat_vx_APCP03h"
  NNODES_RUN_MET_ENSEMBLESTAT_VX_APCP03H: 1
  PPN_RUN_MET_ENSEMBLESTAT_VX_APCP03H: 1
  MEM_RUN_MET_ENSEMBLESTAT_VX_APCP03H: 2G
  WTIME_RUN_MET_ENSEMBLESTAT_VX_APCP03H: 01:00:00
  MAXTRIES_RUN_MET_ENSEMBLESTAT_VX_APCP03H: 2

#----------------------------
# run_met_ensemblestat_vx_apcp06h config parameters
#-----------------------------
task_run_met_ensemblestat_vx_apcp06h:
  TN_RUN_MET_ENSEMBLESTAT_VX_APCP06H: "run_MET_EnsembleStat_vx_APCP06h"
  NNODES_RUN_MET_ENSEMBLESTAT_VX_APCP06H: 1
  PPN_RUN_MET_ENSEMBLESTAT_VX_APCP06H: 1
  MEM_RUN_MET_ENSEMBLESTAT_VX_APCP06H: 2G
  WTIME_RUN_MET_ENSEMBLESTAT_VX_APCP06H: 01:00:00
  MAXTRIES_RUN_MET_ENSEMBLESTAT_VX_APCP06H: 2

#----------------------------
# run_met_ensemblestat_vx_apcp24h config parameters
#-----------------------------
task_run_met_ensemblestat_vx_apcp24h:
  TN_RUN_MET_ENSEMBLESTAT_VX_APCP24H: "run_MET_EnsembleStat_vx_APCP24h"
  NNODES_RUN_MET_ENSEMBLESTAT_VX_APCP24H: 1
  PPN_RUN_MET_ENSEMBLESTAT_VX_APCP24H: 1
  MEM_RUN_MET_ENSEMBLESTAT_VX_APCP24H: 2G
  WTIME_RUN_MET_ENSEMBLESTAT_VX_APCP24H: 01:00:00
  MAXTRIES_RUN_MET_ENSEMBLESTAT_VX_APCP24H: 2

#----------------------------
# run_met_ensemblestat_vx_refc config parameters
#-----------------------------
task_run_met_ensemblestat_vx_refc:
  TN_RUN_MET_ENSEMBLESTAT_VX_REFC: "run_MET_EnsembleStat_vx_REFC"
  NNODES_RUN_MET_ENSEMBLESTAT_VX_REFC: 1
  PPN_RUN_MET_ENSEMBLESTAT_VX_REFC: 1
  MEM_RUN_MET_ENSEMBLESTAT_VX_REFC: 2G
  WTIME_RUN_MET_ENSEMBLESTAT_VX_REFC: 01:00:00
  MAXTRIES_RUN_MET_ENSEMBLESTAT_VX_REFC: 2

#----------------------------
# run_met_ensemblestat_vx_retop config parameters
#-----------------------------
task_run_met_ensemblestat_vx_retop:
  TN_RUN_MET_ENSEMBLESTAT_VX_RETOP: "run_MET_EnsembleStat_vx_RETOP"
  NNODES_RUN_MET_ENSEMBLESTAT_VX_RETOP: 1
  PPN_RUN_MET_ENSEMBLESTAT_VX_RETOP: 1
  MEM_RUN_MET_ENSEMBLESTAT_VX_RETOP: 2G
  WTIME_RUN_MET_ENSEMBLESTAT_VX_RETOP: 01:00:00
  MAXTRIES_RUN_MET_ENSEMBLESTAT_VX_RETOP: 2

#----------------------------
# run_met_ensemblestat_vx_sfc config parameters
#-----------------------------
task_run_met_ensemblestat_vx_sfc:
  TN_RUN_MET_ENSEMBLESTAT_VX_SFC: "run_MET_EnsembleStat_vx_SFC"
  NNODES_RUN_MET_ENSEMBLESTAT_VX_SFC: 1
  PPN_RUN_MET_ENSEMBLESTAT_VX_SFC: 1
  MEM_RUN_MET_ENSEMBLESTAT_VX_SFC: 2G
  WTIME_RUN_MET_ENSEMBLESTAT_VX_SFC: 01:00:00
  MAXTRIES_RUN_MET_ENSEMBLESTAT_VX_SFC: 2

#----------------------------
# run_met_ensemblestat_vx_upa config parameters
#-----------------------------
task_run_met_ensemblestat_vx_upa:
  TN_RUN_MET_ENSEMBLESTAT_VX_UPA: "run_MET_EnsembleStat_vx_UPA"
  NNODES_RUN_MET_ENSEMBLESTAT_VX_UPA: 1
  PPN_RUN_MET_ENSEMBLESTAT_VX_UPA: 1
  MEM_RUN_MET_ENSEMBLESTAT_VX_UPA: 2G
  WTIME_RUN_MET_ENSEMBLESTAT_VX_UPA: 01:00:00
  MAXTRIES_RUN_MET_ENSEMBLESTAT_VX_UPA: 2

#----------------------------
# run_met_gridstat_vx_ensmean_apcp01h config parameters
#-----------------------------
task_run_met_gridstat_vx_ensmean_apcp01h:
  TN_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP01H: "run_MET_GridStat_vx_ensmean_APCP01h"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP01H: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP01H: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP01H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP01H: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP01H: 2

#----------------------------
# run_met_gridstat_vx_ensmean_apcp03h config parameters
#-----------------------------
task_run_met_gridstat_vx_ensmean_apcp03h:
  TN_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP03H: "run_MET_GridStat_vx_ensmean_APCP03h"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP03H: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP03H: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP03H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP03H: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP03H: 2

#----------------------------
# run_met_gridstat_vx_ensmean_apcp06h config parameters
#-----------------------------
task_run_met_gridstat_vx_ensmean_apcp06h:
  TN_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP06H: "run_MET_GridStat_vx_ensmean_APCP06h"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP06H: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP06H: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP06H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP06H: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP06H: 2

#----------------------------
# run_met_gridstat_vx_ensmean_apcp24h config parameters
#-----------------------------
task_run_met_gridstat_vx_ensmean_apcp24h:
  TN_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP24H: "run_MET_GridStat_vx_ensmean_APCP24h"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP24H: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP24H: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP24H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP24H: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSMEAN_APCP24H: 2

#----------------------------
# run_met_pointstat_vx_ensmean_sfc config parameters
#-----------------------------
task_run_met_pointstat_vx_ensmean_sfc:
  TN_RUN_MET_POINTSTAT_VX_ENSMEAN_SFC: "run_MET_PointStat_vx_ensmean_SFC"
  NNODES_RUN_MET_POINTSTAT_VX_ENSMEAN_SFC: 1
  PPN_RUN_MET_POINTSTAT_VX_ENSMEAN_SFC: 1
  MEM_RUN_MET_POINTSTAT_VX_ENSMEAN_SFC: 2G
  WTIME_RUN_MET_POINTSTAT_VX_ENSMEAN_SFC: 01:00:00
  MAXTRIES_RUN_MET_POINTSTAT_VX_ENSMEAN_SFC: 2

#----------------------------
# run_met_pointstat_vx_ensmean_upa config parameters
#-----------------------------
task_run_met_pointstat_vx_ensmean_upa:
  TN_RUN_MET_POINTSTAT_VX_ENSMEAN_UPA: "run_MET_PointStat_vx_ensmean_UPA"
  NNODES_RUN_MET_POINTSTAT_VX_ENSMEAN_UPA: 1
  PPN_RUN_MET_POINTSTAT_VX_ENSMEAN_UPA: 1
  MEM_RUN_MET_POINTSTAT_VX_ENSMEAN_UPA: 2G
  WTIME_RUN_MET_POINTSTAT_VX_ENSMEAN_UPA: 01:00:00
  MAXTRIES_RUN_MET_POINTSTAT_VX_ENSMEAN_UPA: 2

#----------------------------
# run_met_gridstat_vx_ensprob_apcp01h config parameters
#-----------------------------
task_run_met_gridstat_vx_ensprob_apcp01h:
  TN_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP01H: "run_MET_GridStat_vx_ensprob_APCP01h"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP01H: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP01H: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP01H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP01H: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP01H: 2

#----------------------------
# run_met_gridstat_vx_ensprob_apcp03h config parameters
#-----------------------------
task_run_met_gridstat_vx_ensprob_apcp03h:
  TN_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP03H: "run_MET_GridStat_vx_ensprob_APCP03h"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP03H: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP03H: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP03H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP03H: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP03H: 2

#----------------------------
# run_met_gridstat_vx_ensprob_apcp06h config parameters
#-----------------------------
task_run_met_gridstat_vx_ensprob_apcp06h:
  TN_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP06H: "run_MET_GridStat_vx_ensprob_APCP06h"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP06H: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP06H: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP06H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP06H: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP06H: 2

#----------------------------
# run_met_gridstat_vx_ensprob_apcp24h config parameters
#-----------------------------
task_run_met_gridstat_vx_ensprob_apcp24h:
  TN_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP24H: "run_MET_GridStat_vx_ensprob_APCP24h"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP24H: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP24H: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP24H: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP24H: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSPROB_APCP24H: 2

#----------------------------
# run_met_gridstat_vx_ensprob_refc config parameters
#-----------------------------
task_run_met_gridstat_vx_ensprob_refc:
  TN_RUN_MET_GRIDSTAT_VX_ENSPROB_REFC: "run_MET_GridStat_vx_ensprob_REFC"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSPROB_REFC: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSPROB_REFC: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSPROB_REFC: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSPROB_REFC: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSPROB_REFC: 2

#----------------------------
# run_met_gridstat_vx_ensprob_retop config parameters
#-----------------------------
task_run_met_gridstat_vx_ensprob_retop:
  TN_RUN_MET_GRIDSTAT_VX_ENSPROB_RETOP: "run_MET_GridStat_vx_ensprob_RETOP"
  NNODES_RUN_MET_GRIDSTAT_VX_ENSPROB_RETOP: 1
  PPN_RUN_MET_GRIDSTAT_VX_ENSPROB_RETOP: 1
  MEM_RUN_MET_GRIDSTAT_VX_ENSPROB_RETOP: 2G
  WTIME_RUN_MET_GRIDSTAT_VX_ENSPROB_RETOP: 01:00:00
  MAXTRIES_RUN_MET_GRIDSTAT_VX_ENSPROB_RETOP: 2

#----------------------------
# run_met_pointstat_vx_ensprob_sfc config parameters
#-----------------------------
task_run_met_pointstat_vx_ensprob_sfc:
  TN_RUN_MET_POINTSTAT_VX_ENSPROB_SFC: "run_MET_PointStat_vx_ensprob_SFC"
  NNODES_RUN_MET_POINTSTAT_VX_ENSPROB_SFC: 1
  PPN_RUN_MET_POINTSTAT_VX_ENSPROB_SFC: 1
  MEM_RUN_MET_POINTSTAT_VX_ENSPROB_SFC: 2G
  WTIME_RUN_MET_POINTSTAT_VX_ENSPROB_SFC: 01:00:00
  MAXTRIES_RUN_MET_POINTSTAT_VX_ENSPROB_SFC: 2

#----------------------------
# run_met_pointstat_vx_ensprob_upa config parameters
#-----------------------------
task_run_met_pointstat_vx_ensprob_upa:
  TN_RUN_MET_POINTSTAT_VX_ENSPROB_UPA: "run_MET_PointStat_vx_ensprob_UPA"
  NNODES_RUN_MET_POINTSTAT_VX_ENSPROB_UPA: 1
  PPN_RUN_MET_POINTSTAT_VX_ENSPROB_UPA: 1
  MEM_RUN_MET_POINTSTAT_VX_ENSPROB_UPA: 2G
  WTIME_RUN_MET_POINTSTAT_VX_ENSPROB_UPA: 01:00:00
  MAXTRIES_RUN_MET_POINTSTAT_VX_ENSPROB_UPA: 2

#----------------------------
# GRAPHICS config parameters
#-----------------------------
task_run_graphics:
  TN_RUN_GRAPHICS: "run_graphics"
  NNODES_RUN_GRAPHICS: 1
  PPN_RUN_GRAPHICS: 12
  WTIME_RUN_GRAPHICS: 00:30:00
  MAXTRIES_RUN_GRAPHICS: 1
  #
  #-----------------------------------------------------------------------
  #
  # Set the tiles (or subdomains) for creating graphics in a Rocoto metatask.
  # Do not include references to the grids that are produced in separate grib
  # files (set with ADDNL_OUTPUT_GRIDS above). Those will be added in setup.sh
  #
  # TILE_LABELS
  # A space separated list (string is fine, no need for array) of the labels
  # applied to the groupings of tiles to be run as a single batch jobs. For
  # example, you may label the set of tiles SE,NE,SC,NC,SW,NW as "regions", and
  # the full input domain as "full" if you wanted those to run in two domains. The
  # length must match the length of TILE_SETS.
  #
  # TILE_SETS
  # A space separated list of tile groupings to plot. Space-separated sets
  # indicate which ones will be grouped in a single batch job, comma sepated items
  # are the tiles to be plotted in that batch job. For example:
  #    TILE_SETS="full SW,SC,SE NW,NC,NE"
  #    TILE_LABELS="full southern_regions northern_regions"
  # would plot maps for the full domain in a batch job separately from the
  # southern regions, using a third batch job for the northern regions. The
  # space-separated list must match the length of TILE_LABELS.
  #
  #-----------------------------------------------------------------------
  #
  TILE_LABELS: "full"
  TILE_SETS: "full"

#----------------------------
# CLEAN config parameters
#-----------------------------
task_run_clean:
  TN_RUN_CLEAN: "run_clean"
  NNODES_RUN_CLEAN: 1
  PPN_RUN_CLEAN: 1
  MEM_RUN_CLEAN: 2G
  WTIME_RUN_CLEAN: 00:15:00
  MAXTRIES_RUN_CLEAN: 1
  #
  #-----------------------------------------------------------------------
  #
  # Parameters for cleaning the real-time and retrospective runs.
  # CLEAN_OLDPROD_HRS:
  #   the product under com directory from cycles older than (current cycle - this hour) will be cleaned 
  # CLEAN_OLDLOG_HRS
  #   the log files under com directory from cycles older than (current cycle - this hour) will be cleaned 
  # CLEAN_OLDRUN_HRS
  #   the run directory under tmpnwprd directory from cycles older than (current cycle - this hour) will be cleaned 
  # CLEAN_OLDFCST_HRS
  #   the fv3lam forecast netcdf files forecast run directory from cycles older than (current cycle - this hour) will be cleaned 
  # CLEAN_OLDSTMP_HRS
  #   the postprd GRIB-2 files from cycles older than (current cycle - this hour) will be cleaned 
  #-----------------------------------------------------------------------
  #
  CLEAN_OLDPROD_HRS: 72
  CLEAN_OLDLOG_HRS: 72
  CLEAN_OLDRUN_HRS: 48
  CLEAN_OLDFCST_HRS: 24
  CLEAN_OLDSTMPPOST_HRS: 24
  CLEAN_NWGES_HRS: 72

#----------------------------
# ARCHIVE config parameters
#-----------------------------
task_run_archive:
  TN_RUN_ARCHIVE: "run_archive"
  NNODES_RUN_ARCHIVE: 1
  PPN_RUN_ARCHIVE: 1
  MEM_RUN_ARCHIVE: 24G
  WTIME_RUN_ARCHIVE: 23:00:00
  MAXTRIES_RUN_ARCHIVE: 1

#----------------------------
# ENSPOST config parameters
#-----------------------------
task_run_enspost:
  TN_RUN_ENSPOST: "run_enspost"
  NNODES_RUN_ENSPOST: 1
  PPN_RUN_ENSPOST: 1
  WTIME_RUN_ENSPOST: 00:30:00
  MAXTRIES_RUN_ENSPOST: 1
#----------------------------
# AQM_ICS config parameters
#-----------------------------
task_aqm_ics:
  TN_AQM_ICS: "aqm_ics"
  NNODES_AQM_ICS: 1
  PPN_AQM_ICS: 1
  WTIME_AQM_ICS: 00:30:00
  MAXTRIES_AQM_ICS: 2

#----------------------------
# AQM_LBCS config parameters
#-----------------------------
task_aqm_lbcs:
  TN_AQM_LBCS: "aqm_lbcs"
  NNODES_AQM_LBCS: 1
  PPN_AQM_LBCS: 24
  WTIME_AQM_LBCS: 00:30:00
  MAXTRIES_AQM_LBCS: 2

#----------------------------
# NEXUS_GFS_SFC config parameters
#-----------------------------
task_nexus_gfs_sfc:
  TN_NEXUS_GFS_SFC: "nexus_gfs_sfc"
  NNODES_NEXUS_GFS_SFC: 1
  PPN_NEXUS_GFS_SFC: 1
  MEM_NEXUS_GFS_SFC: 2G
  WTIME_NEXUS_GFS_SFC: 00:30:00
  MAXTRIES_NEXUS_GFS_SFC: 2

#----------------------------
# NEXUS_EMISSION config parameters
#-----------------------------
task_nexus_emission:
  TN_NEXUS_EMISSION: "nexus_emission"
  NNODES_NEXUS_EMISSION: 4
  PPN_NEXUS_EMISSION: '{{ platform.NCORES_PER_NODE // OMP_NUM_THREADS_NEXUS_EMISSION }}'
  WTIME_NEXUS_EMISSION: 01:00:00
  MAXTRIES_NEXUS_EMISSION: 2
  KMP_AFFINITY_NEXUS_EMISSION: "scatter"
  OMP_NUM_THREADS_NEXUS_EMISSION: 2
  OMP_STACKSIZE_NEXUS_EMISSION: "1024m"

#----------------------------
# NEXUS_POST_SPLIT config parameters
#-----------------------------
task_nexus_post_split:
  TN_NEXUS_POST_SPLIT: "nexus_post_split"
  NNODES_NEXUS_POST_SPLIT: 1
  PPN_NEXUS_POST_SPLIT: 1
  WTIME_NEXUS_POST_SPLIT: 00:30:00
  MAXTRIES_NEXUS_POST_SPLIT: 2

#----------------------------
# FIRE_EMISSION config parameters
#-----------------------------
task_fire_emission:
  TN_FIRE_EMISSION: "fire_emission"
  NNODES_FIRE_EMISSION: 1
  PPN_FIRE_EMISSION: 1
  MEM_FIRE_EMISSION: 2G
  WTIME_FIRE_EMISSION: 00:30:00
  MAXTRIES_FIRE_EMISSION: 2

#----------------------------
# POINT_SOURCE config parameters
#-----------------------------
task_point_source:
  TN_POINT_SOURCE: "point_source"
  NNODES_POINT_SOURCE: 1
  PPN_POINT_SOURCE: 1 
  WTIME_POINT_SOURCE: 01:00:00
  MAXTRIES_POINT_SOURCE: 2

#----------------------------
# PRE_POST_STAT config parameters
#-----------------------------
task_pre_post_stat:
  TN_PRE_POST_STAT: "pre_post_stat"
  NNODES_PRE_POST_STAT: 1
  PPN_PRE_POST_STAT: 1
  WTIME_PRE_POST_STAT: 00:30:00
  MAXTRIES_PRE_POST_STAT: 2

#----------------------------
# POST_STAT_O3 config parameters
#-----------------------------
task_post_stat_o3:
  TN_POST_STAT_O3: "post_stat_o3"
  NNODES_POST_STAT_O3: 1
  PPN_POST_STAT_O3: 1
  MEM_POST_STAT_O3: 120G 
  WTIME_POST_STAT_O3: 00:30:00
  MAXTRIES_POST_STAT_O3: 2
  KMP_AFFINITY_POST_STAT_O3: "scatter"
  OMP_NUM_THREADS_POST_STAT_O3: 1
  OMP_STACKSIZE_POST_STAT_O3: "2056M"

#----------------------------
# POST_STAT_PM25 config parameters
#-----------------------------
task_post_stat_pm25:
  TN_POST_STAT_PM25: "post_stat_pm25"
  NNODES_POST_STAT_PM25: 1
  PPN_POST_STAT_PM25: 1
  MEM_POST_STAT_PM25: 120G
  WTIME_POST_STAT_PM25: 00:30:00
  MAXTRIES_POST_STAT_PM25: 2
  KMP_AFFINITY_POST_STAT_PM25: "scatter"
  OMP_NUM_THREADS_POST_STAT_PM25: 1
  OMP_STACKSIZE_POST_STAT_PM25: "2056M"

#----------------------------
# BIAS_CORRECTION_O3 config parameters
#-----------------------------
task_bias_correction_o3:
  TN_BIAS_CORRECTION_O3: "bias_correction_o3"
  NNODES_BIAS_CORRECTION_O3: 1
  PPN_BIAS_CORRECTION_O3: 1
  MEM_BIAS_CORRECTION_O3: 120G
  WTIME_BIAS_CORRECTION_O3: 00:30:00
  MAXTRIES_BIAS_CORRECTION_O3: 2
  KMP_AFFINITY_BIAS_CORRECTION_O3: "scatter"
  OMP_NUM_THREADS_BIAS_CORRECTION_O3: 128
  OMP_STACKSIZE_BIAS_CORRECTION_O3: "2056M"

#----------------------------
# BIAS_CORRECTION_PM25 config parameters
#-----------------------------
task_bias_correction_pm25:
  TN_BIAS_CORRECTION_PM25: "bias_correction_pm25"
  NNODES_BIAS_CORRECTION_PM25: 1
  PPN_BIAS_CORRECTION_PM25: 1
  MEM_BIAS_CORRECTION_PM25: 120G
  WTIME_BIAS_CORRECTION_PM25: 00:30:00
  MAXTRIES_BIAS_CORRECTION_PM25: 2
  KMP_AFFINITY_BIAS_CORRECTION_PM25: "scatter"
  OMP_NUM_THREADS_BIAS_CORRECTION_PM25: 128
  OMP_STACKSIZE_BIAS_CORRECTION_PM25: "2056M"

#----------------------------
# global config parameters
#-----------------------------
global:
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters associated with outputting satellite fields in the UPP
  # grib2 files using the Community Radiative Transfer Model (CRTM).
  #
  # USE_CRTM:
  # Flag that defines whether external CRTM coefficient files have been
  # staged by the user in order to output synthetic satellite products
  # available within the UPP. If this is set to true, then the workflow
  # will check for these files in the directory FIXcrtm. Otherwise, it is
  # assumed that no satellite fields are being requested in the UPP
  # configuration.
  #
  #-----------------------------------------------------------------------
  #
  USE_CRTM: false
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters associated with running ensembles.  Definitions:
  #
  # NUM_ENS_MEMBERS:
  # The number of ensemble members to run if DO_ENSEMBLE is set to true.
  # This variable also controls the naming of the ensemble member directories.
  # For example, if this is set to 8, the member directories will be named 
  # mem1, mem2, ..., mem8. Not used if DO_ENSEMBLE is set to false.
  #
  # ENSMEM_NAMES:
  # A list of names for the ensemble member names following the format
  # mem001, mem002, etc.
  #
  # FV3_NML_ENSMEM_FPS:
  # Paths to the ensemble member corresponding namelists in the
  # experiment directory
  # 
  # NUM_ENS_MEMBERS_FCST:
  # The number of ensemble members to run forecast if DO_ENSFCST is set to "TRUE",
  # This variable also controls the naming of the ensemble member directories.  
  # For example, if this is set to "8", the member directories will be named 
  # mem1, mem2, ..., mem8.  If it is set to "08" (note the leading zero), 
  # the member directories will be named mem01, mem02, ..., mem08.  Note, 
  # however, that after reading in the number of characters in this string
  # (in order to determine how many leading zeros, if any, should be placed
  # in the names of the member directories), the workflow generation scripts
  # strip away those leading zeros.  Thus, in the variable definitions file 
  # (GLOBAL_VAR_DEFNS_FN), this variable appear with its leading zeros 
  # stripped.  This variable is not used if DO_ENSEMBLE is not set to "TRUE".
  # 
  #-----------------------------------------------------------------------
  #
  NUM_ENS_MEMBERS: 0
  NUM_ENS_MEMBERS_FCST: 0
  ENSMEM_NAMES: '{% for m in range(NUM_ENS_MEMBERS) %} "mem%03d, " % m {% endfor %}'
  FV3_NML_ENSMEM_FPS: '{% for mem in ENSMEM_NAMES %}{{ [EXPTDIR, "%s_%s" % FV3_NML_FN, mem]|path_join }}{% endfor %}'
  #
  #-----------------------------------------------------------------------
  #
  # Set default ad-hoc stochastic physics options.
  # For detailed documentation of these parameters, see:
  # https://stochastic-physics.readthedocs.io/en/ufs_public_release/namelist_options.html
  #
  #-----------------------------------------------------------------------
  #
  DO_SHUM: false
  DO_SPPT: false
  DO_SKEB: false
  ISEED_SPPT: 1
  ISEED_SHUM: 2
  ISEED_SKEB: 3
  NEW_LSCALE: true
  SHUM_MAG: 0.006 #Variable "shum" in input.nml
  SHUM_LSCALE: 150000
  SHUM_TSCALE: 21600 #Variable "shum_tau" in input.nml
  SHUM_INT: 3600 #Variable "shumint" in input.nml
  SPPT_MAG: 0.7 #Variable "sppt" in input.nml
  SPPT_LOGIT: true
  SPPT_LSCALE: 150000
  SPPT_TSCALE: 21600 #Variable "sppt_tau" in input.nml
  SPPT_INT: 3600 #Variable "spptint" in input.nml
  SPPT_SFCLIMIT: true
  SKEB_MAG: 0.5 #Variable "skeb" in input.nml
  SKEB_LSCALE: 150000
  SKEB_TSCALE: 21600 #Variable "skeb_tau" in input.nml
  SKEB_INT: 3600 #Variable "skebint" in input.nml
  SKEBNORM: 1
  SKEB_VDOF: 10
  USE_ZMTNBLCK: false
  #
  #-----------------------------------------------------------------------
  #
  # Set default SPP stochastic physics options. Each SPP option is an array, 
  # applicable (in order) to the scheme/parameter listed in SPP_VAR_LIST. 
  # Enter each value of the array in config.yaml as shown below without commas
  # or single quotes (e.g., SPP_VAR_LIST=( "pbl" "sfc" "mp" "rad" "gwd" ). 
  # Both commas and single quotes will be added by Jinja when creating the
  # namelist.
  #
  # Note that SPP is currently only available for specific physics schemes 
  # used in the RAP/HRRR physics suite.  Users need to be aware of which SDF
  # is chosen when turning this option on. 
  #
  # Patterns evolve and are applied at each time step.
  #
  #-----------------------------------------------------------------------
  #
  DO_SPP: false
  SPP_VAR_LIST: [ "pbl", "sfc", "mp", "rad", "gwd" ]
  SPP_MAG_LIST: [ 0.2, 0.2, 0.75, 0.2, 0.2 ] #Variable "spp_prt_list" in input.nml
  SPP_LSCALE: [ 150000.0, 150000.0, 150000.0, 150000.0, 150000.0 ]
  SPP_TSCALE: [ 21600.0, 21600.0, 21600.0, 21600.0, 21600.0 ] #Variable "spp_tau" in input.nml
  SPP_SIGTOP1: [ 0.1, 0.1, 0.1, 0.1, 0.1 ]
  SPP_SIGTOP2: [ 0.025, 0.025, 0.025, 0.025, 0.025 ]
  SPP_STDDEV_CUTOFF: [ 1.5, 1.5, 2.5, 1.5, 1.5 ]
  ISEED_SPP: [ 4, 5, 6, 7, 8 ]
  #
  #-----------------------------------------------------------------------
  #
  # Turn on SPP in Noah or RUC LSM (support for Noah MP is in progress).
  # Please be aware of the SDF that you choose if you wish to turn on LSM
  # SPP.
  #
  # SPP in LSM schemes is handled in the &nam_sfcperts namelist block 
  # instead of in &nam_sppperts, where all other SPP is implemented.
  #
  # Perturbations to soil moisture content (SMC) are only applied at the 
  # first time step.
  #
  # LSM perturbations include SMC - soil moisture content (volume fraction),
  # VGF - vegetation fraction, ALB - albedo, SAL - salinity, 
  # EMI - emissivity, ZOL - surface roughness (cm), and STC - soil temperature.
  #
  # Only five perturbations at a time can be applied currently, but all seven
  # are shown below.  In addition, only one unique iseed value is allowed 
  # at the moment, and is used for each pattern.
  #
  DO_LSM_SPP: false #If true, sets lndp_type=2
  LSM_SPP_TSCALE: [ 21600, 21600, 21600, 21600, 21600, 21600, 21600 ]
  LSM_SPP_LSCALE: [ 150000, 150000, 150000, 150000, 150000, 150000, 150000 ]
  ISEED_LSM_SPP: [ 9 ]
  LSM_SPP_VAR_LIST: [ "smc", "vgf", "alb", "sal", "emi", "zol", "stc" ]
  LSM_SPP_MAG_LIST: [ 0.017, 0.001, 0.001, 0.001, 0.001, 0.001, 0.2 ]
  #
  #-----------------------------------------------------------------------
  # 
  # HALO_BLEND:
  # Number of rows into the computational domain that should be blended 
  # with the LBCs.  To shut halo blending off, this can be set to zero.
  #
  #-----------------------------------------------------------------------
  #
  HALO_BLEND: 10
  #
  #-----------------------------------------------------------------------
  # 
  # PRINT_DIFF_PGR:
  # Option to turn on/off pressure tendency diagnostic
  #
  #-----------------------------------------------------------------------
  #
  PRINT_DIFF_PGR: false
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters associated with running data assimilation.  Definitions:
  #
  # SURFACE_CYCLE_DELAY_HRS:
  # The surface cycle usually happens in cold start cycle. But there is
  # a need to delay surface cycle to the warm start cycle following the
  # cold start cycle. This one sets how many hours we want the surface
  # cycle being delayed.
  #
  # USE_RRFSE_ENS:
  # Use rrfse ensemble for hybrid analysis
  #
  #-----------------------------------------------------------------------
  #
  SURFACE_CYCLE_DELAY_HRS: 1
  USE_RRFSE_ENS: false
  #
  #-----------------------------------------------------------------------
  #
  # Set parameters associated with running retrospective experiments.  Definitions:
  #
  # LBCS_ICS_ONLY:
  # Flag turn on the runs prepare boundary and cold start initial conditions in
  #      retrospective experiments.
  #
  #-----------------------------------------------------------------------
  #
  LBCS_ICS_ONLY: false

#----------------------------
# verification parameters
#
# VX_FCST_MODEL_NAME:
# String that specifies a descriptive name for the model being verified.
# This is used in forming the names of the verification output files as
# well as in the contents of those files.
#
# VX_FCST_INPUT_BASEDIR:
# Location of top-level directory containing forecast (but not obs) files
# that will be used as input into METplus for verification.  If not
# specified, this gets set to EXPTDIR.
#
#-----------------------------
verification:
  VX_FCST_MODEL_NAME: '{{ nco.NET }}.{{ task_run_post.POST_OUTPUT_DOMAIN_NAME }}'
  VX_FCST_INPUT_BASEDIR: '{{ workflow.EXPTDIR if ((workflow_switches.RUN_TASK_RUN_FCST and task_run_fcst.WRITE_DOPOST) or workflow_switches.RUN_TASK_RUN_POST) }}'

#----------------------------
# CPL_AQM config parameters
#-----------------------------
cpl_aqm_parm:
  #
  #-----------------------------------------------------------------------
  #
  # CPL_AQM:
  # Coupling flag for air quality modeling
  #
  # DO_AQM_DUST:
  # Flag turning on/off AQM dust option in AQM_RC
  #
  # DO_AQM_CANOPY
  # Flag turning on/off AQM canopy option in AQM_RC
  # 
  # DO_AQM_PRODUCT
  # Flag turning on/off AQM output products in AQM_RC
  # 
  # DO_AQM_CHEM_LBCS:
  # Add chemical LBCs to chemical LBCs
  # 
  # DO_AQM_GEFS_LBCS:
  # Add GEFS aerosol LBCs to chemical LBCs
  #
  # DO_AQM_SAVE_AIRNOW_HIST:
  # Save bias-correction airnow training data
  #
  # DO_AQM_SAVE_FIRE:
  # Archive fire emission file to HPSS
  #
  # AQM_CONFIG_DIR:
  # Configuration directory for AQM
  # 
  # AQM_BIO_DIR:
  # Path to the directory containing AQM bio files
  # 
  # AQM_BIO_FILE:
  # File name of AQM BIO file
  #
  # AQM_DUST_DIR:
  # Path to the directory containing AQM dust file
  #
  # AQM_DUST_FILE_PREFIX:
  # Frefix of AQM dust file
  #
  # AQM_DUST_FILE_SUFFIX:
  # Suffix and extension of AQM dust file
  #
  # AQM_CANOPY_DIR:
  # Path to the directory containing AQM canopy files
  # 
  # AQM_CANOPY_FILE_PREFIX:
  # File name of AQM canopy file
  #
  # AQM_CANOPY_FILE_SUFFIX:
  # Suffix and extension of AQM CANOPY file
  # 
  # AQM_FIRE_DIR:
  # Path to the directory containing AQM fire files
  # 
  # AQM_FIRE_FILE_PREFIX:
  # Prefix of AQM FIRE file
  # 
  # AQM_FIRE_FILE_SUFFIX:
  # Suffix and extension of AQM FIRE file
  #
  # AQM_FIRE_ARCHV_DIR:
  # Path to the archive directory for RAVE emission files on HPSS
  #
  # AQM_RC_FIRE_FREQUENCY:
  # Fire frequency in aqm.rc
  #
  # AQM_RC_PRODUCT_FN:
  # File name of AQM output products
  #
  # AQM_RC_PRODUCT_FREQUENCY:
  # Frequency of AQM output products
  #
  # AQM_LBCS_DIR:
  # Path to the directory containing chemical LBC files
  # 
  # AQM_LBCS_FILES:
  # File name of chemical LBCs
  #
  # AQM_GEFS_DIR:
  # Path to the directory containing GEFS aerosol LBC files
  #
  # AQM_GEFS_FILE_PREFIX:
  # Prefix of AQM GEFS file ("geaer" or "gfs")
  #
  # AQM_GEFS_FILE_CYC:
  # Cycle of the GEFS aerosol LBC files only if it is fixed
  # 
  # NEXUS_INPUT_DIR:
  # Same as GRID_DIR but for the the air quality emission generation task.
  # Should be blank for the default value specified in setup.sh
  # 
  # NEXUS_FIX_DIR:
  # Directory containing grid_spec files as the input file of nexus
  # 
  # NEXUS_GRID_FN:
  # File name of the input grid_spec file of nexus
  #
  # NUM_SPLIT_NEXUS:
  # Number of split nexus emission tasks
  #
  # NEXUS_GFS_SFC_OFFSET_HRS: 0
  # Time offset when retrieving gfs surface data files
  # 
  # NEXUS_GFS_SFC_DIR:
  # Path to directory containing GFS surface data files
  # This is set to COMINgfs when DO_REAL_TIME=TRUE. 
  #
  # NEXUS_GFS_SFC_ARCHV_DIR: 
  # Path to archive directory for gfs surface files on HPSS
  #
  # PT_SRC_BASEDIR:
  # Parent directory containing point source files for CONUS/AK/HI
  #
  # AQM_AIRNOW_HIST_DIR:
  # Path to the directory where the historical AIRNOW data are located
  #
  #-----------------------------------------------------------------------
  #
  CPL_AQM: false

  DO_AQM_DUST: true
  DO_AQM_CANOPY: false
  DO_AQM_PRODUCT: true
  DO_AQM_CHEM_LBCS: true
  DO_AQM_GEFS_LBCS: false
  DO_AQM_SAVE_AIRNOW_HIST: false
  DO_AQM_SAVE_FIRE: false

  AQM_CONFIG_DIR: ""
  AQM_BIO_DIR: ""
  AQM_BIO_FILE: "BEIS_SARC401.ncf"

  AQM_DUST_DIR: "/path/to/dust/dir"
  AQM_DUST_FILE_PREFIX: "FENGSHA_p8_10km_inputs"
  AQM_DUST_FILE_SUFFIX: ".nc"

  AQM_CANOPY_DIR: "/path/to/canopy/dir"
  AQM_CANOPY_FILE_PREFIX: "gfs.t12z.geo"
  AQM_CANOPY_FILE_SUFFIX: ".canopy_regrid.nc"

  AQM_FIRE_DIR: ""
  AQM_FIRE_FILE_PREFIX: "GBBEPx_C401GRID.emissions_v003"
  AQM_FIRE_FILE_SUFFIX: ".nc"
  AQM_FIRE_FILE_OFFSET_HRS: 0
  AQM_FIRE_ARCHV_DIR: "/path/to/archive/dir/for/RAVE/on/HPSS"

  AQM_RC_FIRE_FREQUENCY: "static"
  AQM_RC_PRODUCT_FN: "aqm.prod.nc"
  AQM_RC_PRODUCT_FREQUENCY: "hourly"

  AQM_LBCS_DIR: ""
  AQM_LBCS_FILES: "gfs_bndy_chen_<MM>.tile7.000.nc"

  AQM_GEFS_DIR: ""
  AQM_GEFS_FILE_PREFIX: "geaer"
  AQM_GEFS_FILE_CYC: ""

  NEXUS_INPUT_DIR: ""
  NEXUS_FIX_DIR: ""
  NEXUS_GRID_FN: "grid_spec_GSD_HRRR_25km.nc"
  NUM_SPLIT_NEXUS: 3
  NEXUS_GFS_SFC_OFFSET_HRS: 0
  NEXUS_GFS_SFC_DIR: ""
  NEXUS_GFS_SFC_ARCHV_DIR: "/NCEPPROD/hpssprod/runhistory"

  PT_SRC_BASEDIR: "/path/to/point/source/base/directory/for/conus/hi/ak"

  AQM_AIRNOW_HIST_DIR: "/path/to/historical/airnow/data/dir"
